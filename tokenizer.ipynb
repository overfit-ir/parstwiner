{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tempo.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/overfit-ir/persian-twitter-ner/blob/master/tokenizer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rMbgFS_xcfcf"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nF-7m57sBgdp",
        "outputId": "92438d08-8e4d-4338-c739-e730cc5ab785",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "! pip -q install transformers\n",
        "! pip -q install parsivar"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 1.1MB 2.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.1MB 10.9MB/s \n",
            "\u001b[K     |████████████████████████████████| 890kB 19.4MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.0MB 26.5MB/s \n",
            "\u001b[?25h  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[K     |████████████████████████████████| 36.2MB 82kB/s \n",
            "\u001b[K     |████████████████████████████████| 1.5MB 53.4MB/s \n",
            "\u001b[?25h  Building wheel for parsivar (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for nltk (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GbAOjVTbIvjW"
      },
      "source": [
        "import torch\n",
        "from __future__ import unicode_literals\n",
        "# from hazm import *\n",
        "from parsivar import *\n",
        "from pprint import pprint\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "from scipy import spatial\n",
        "from transformers import AutoConfig, AutoTokenizer, AutoModel, AutoModelForTokenClassification\n",
        "import re\n",
        "parsivar_tokenizer = Tokenizer()\n",
        "parsivar_normalizer = Normalizer()"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZZAJwNKuIwLN",
        "outputId": "6d9bb795-cb72-4491-b520-726e4644bd8f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"HooshvareLab/bert-base-parsbert-uncased\")\n",
        "# tokenizer = AutoTokenizer.from_pretrained(\"HooshvareLab/bert-base-parsbert-ner-uncased\")\n",
        "model = AutoModelForTokenClassification.from_pretrained(\"HooshvareLab/bert-base-parsbert-ner-uncased\")\n",
        "model.eval()\n",
        "print()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h_5tgmwqch8n"
      },
      "source": [
        "# **Tokenize**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DIODPTLFdAzn"
      },
      "source": [
        "### Example"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zQ5WxSUoaZP3"
      },
      "source": [
        "tweet_example = \"\"\" بابا بیخیال :)) همون سال اتلتیکو با گل افساید به بایرن رفت فینال.\n",
        "\n",
        "مشکل داوری نداشتیم اون بازی که میگی.\n",
        "فصل قبلش هم ۴ ۰ با هاینکس زدیم شما رو\n",
        "\"\"\"\n",
        "\n",
        "tweet_example2 = \"\"\"\n",
        " محسن رضایی هم یک جوان ۲۶،۲۷ ساله بوده\n",
        "مدیریت جنگ با مدیریت فعلی کشور که اکثرا افراد لیبرابی هستن که در جنگ هیچ نقشی نداشتن و یا نهایتا پشت جبهه مشغول بودن قابل مقایسه نیست\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "tweet_example3 = \"\"\"\n",
        "سلام\n",
        "خواهر من فکر کنم دو سالی سرفه امانش را بریده بود.خیلی کارها کرد برای درمانش اما درست نشد که نشد. کرونا هم که شروع شد، خیلی نگرانش بودیم. \n",
        "چند روز پیش با چند تا نیش زنبور عسل به اصطلاح زنبور درمانی کرد و با کمال تعجب دیگه سرفه نمی کنه.\n",
        "\n",
        "\"\"\""
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CE2zhzuFQnNG",
        "outputId": "0e829c51-1bbf-4e93-ca7b-59cc5dae039a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 986
        }
      },
      "source": [
        "input_sentence = tokenizer.tokenize(tweet_example3)\n",
        "for token in input_sentence:\n",
        "  print(token)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "سلام\n",
            "خواهر\n",
            "من\n",
            "فکر\n",
            "کنم\n",
            "دو\n",
            "سالی\n",
            "سرفه\n",
            "امانش\n",
            "را\n",
            "بریده\n",
            "بود\n",
            ".\n",
            "خیلی\n",
            "کارها\n",
            "کرد\n",
            "برای\n",
            "درمانش\n",
            "اما\n",
            "درست\n",
            "نشد\n",
            "که\n",
            "نشد\n",
            ".\n",
            "کرونا\n",
            "هم\n",
            "که\n",
            "شروع\n",
            "شد\n",
            "،\n",
            "خیلی\n",
            "نگرانش\n",
            "بودیم\n",
            ".\n",
            "چند\n",
            "روز\n",
            "پیش\n",
            "با\n",
            "چند\n",
            "تا\n",
            "نیش\n",
            "زنبور\n",
            "عسل\n",
            "به\n",
            "اصطلاح\n",
            "زنبور\n",
            "درمانی\n",
            "کرد\n",
            "و\n",
            "با\n",
            "کمال\n",
            "تعجب\n",
            "دیگه\n",
            "سرفه\n",
            "نمی\n",
            "کنه\n",
            ".\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kO4g0ZuCN9WM",
        "outputId": "0c9b622e-eb98-4de8-f77c-8335ca6e3291",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 935
        }
      },
      "source": [
        "for token in parsivar_tokenizer.tokenize_words(parsivar_normalizer.normalize(tweet_example3)):\n",
        "  print(token)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "سلام\n",
            "خواهر\n",
            "من\n",
            "فکر\n",
            "کنم\n",
            "دو\n",
            "سالی\n",
            "سرفه\n",
            "امانش\n",
            "را\n",
            "بریده‌بود\n",
            ".\n",
            "خیلی\n",
            "کارها\n",
            "کرد\n",
            "برای\n",
            "درمانش\n",
            "اما\n",
            "درست\n",
            "نشد\n",
            "که\n",
            "نشد\n",
            ".\n",
            "کرونا\n",
            "هم\n",
            "که\n",
            "شروع\n",
            "شد\n",
            "،\n",
            "خیلی\n",
            "نگرانش‌بودیم\n",
            ".\n",
            "چند\n",
            "روز\n",
            "پیش\n",
            "با\n",
            "چند\n",
            "تا\n",
            "نیش\n",
            "زنبور\n",
            "عسل\n",
            "به\n",
            "اصطلاح\n",
            "زنبور\n",
            "درمانی\n",
            "کرد\n",
            "و\n",
            "با\n",
            "کمال\n",
            "تعجب\n",
            "دیگه\n",
            "سرفه\n",
            "نمی‌کنه\n",
            ".\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CmwTpkbxdEGv"
      },
      "source": [
        "### Tokenize All tweets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "naQ5Dy8tdN4M",
        "outputId": "0a0c0f20-5fee-436e-a8d6-1f847339c214",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "source": [
        "! wget \"https://raw.githubusercontent.com/overfit-ir/persian-twitter-ner/master/twitter_data/extracted_data.txt\""
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-10-05 05:33:53--  https://raw.githubusercontent.com/overfit-ir/persian-twitter-ner/master/twitter_data/extracted_data.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2051971 (2.0M) [text/plain]\n",
            "Saving to: ‘extracted_data.txt’\n",
            "\n",
            "extracted_data.txt  100%[===================>]   1.96M  9.44MB/s    in 0.2s    \n",
            "\n",
            "2020-10-05 05:33:54 (9.44 MB/s) - ‘extracted_data.txt’ saved [2051971/2051971]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "01jhD-R-dXsn",
        "outputId": "f87d516f-0fbc-4f3e-d38b-446e980a523e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 717
        }
      },
      "source": [
        "! head -n 40 extracted_data.txt"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  سلام\n",
            "خواهر من فکر کنم دو سالی سرفه امانش را بریده بود.خیلی کارها کرد برای درمانش اما درست نشد که نشد. کرونا هم که شروع شد، خیلی نگرانش بودیم. \n",
            "چند روز پیش با چند تا نیش زنبور عسل به اصطلاح زنبور درمانی کرد و با کمال تعجب دیگه سرفه نمی کنه.\n",
            "\n",
            "**************\n",
            "\n",
            "ولادتِ حضرت امام موسی کاظمؑ \n",
            "\n",
            "**************\n",
            "\n",
            "iran iranelection  - و صدای شیون فرزندانت که وحشت زده گریه می‌کردند؛ نوشته‌ی مهرزاد محب‌پور همسر مژگان عبادی بهای... \n",
            "\n",
            "**************\n",
            "\n",
            " Iran IranElection صبا محب‌پور، جوان محروم از تحصیل بهایی: «قانون، تنها عنوانی حک شده در کنار نام سرزمین من ایران است»\n",
            "\n",
            "**************\n",
            "\n",
            "  محسن رضایی هم یک جوان ۲۶،۲۷ ساله بوده\n",
            "مدیریت جنگ با مدیریت فعلی کشور که اکثرا افراد لیبرابی هستن که در جنگ هیچ نقشی نداشتن و یا نهایتا پشت جبهه مشغول بودن قابل مقایسه نیست\n",
            "\n",
            "**************\n",
            "\n",
            " حسین باستانی یه مستند ساخته به اسم کودتای خزنده که بر اساس نوار درز کرده یه جلسه یه سری فرمانده‌ها در وسط جنگه با محسن رضایی (فرمانده کل سپاه تو اون زمان). تو اون جلسه فرمانده‌ها کلی شاکی‌ن از بی‌کفایتی یه سری از رده‌بالایی‌ها و باقی قصه...\n",
            "\n",
            "\n",
            "\n",
            "**************\n",
            "\n",
            "میگن سعادتمند بخاطر مذاکره میخواد بره المان، بنظرم ی تور جهانگردی واس خودش گذاشته\n",
            "استراماچونی_را_برگردانید\n",
            "\n",
            "**************\n",
            "\n",
            " من بیشتر بحث های اعتقادی و گفتگوهاشو با نیری گوش میدم.\n",
            "فلاکتهای ایرانیها گاهی واااقعا داغونه. فقط یک بار یک دختری زنگ زد که گفت از ۱۷ سالگی جهانگردی میکنه.یعنی هلاکویی کف کرده بود از حرف زدن باهاش اینقدر دختره میزون بود :))))\n",
            "\n",
            "**************\n",
            "\n",
            " یه زمانی هم هوادارا تو توئیتر کاملا راضی و خوشحال بودن که قراره ۷۰/۸۰ تا خرجش کنیم \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ky_SVWj-d9K5",
        "outputId": "209af249-2509-4da6-ef50-8ccdf79483e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "tweets_str = \"\"\n",
        "with open(\"extracted_data.txt\") as file:\n",
        "  for line in file.readlines():\n",
        "    tweets_str += line\n",
        "tweets_str[:20]"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'  سلام\\nخواهر من فکر '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pqt4gc0LeiY7",
        "outputId": "2b0f0ca0-0e78-4148-a47d-226226cdcc9f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "tweets = tweets_str.split(\"\\n\\n**************\\n\\n\")\n",
        "tweets[0], len(tweets)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('  سلام\\nخواهر من فکر کنم دو سالی سرفه امانش را بریده بود.خیلی کارها کرد برای درمانش اما درست نشد که نشد. کرونا هم که شروع شد، خیلی نگرانش بودیم. \\nچند روز پیش با چند تا نیش زنبور عسل به اصطلاح زنبور درمانی کرد و با کمال تعجب دیگه سرفه نمی کنه.',\n",
              " 6978)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FyTcsd452GaG",
        "outputId": "af421026-7e9b-40f7-d1d2-2fca9fdbad80",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(tweets)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6978"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PvVwD5co44yA",
        "outputId": "65c4bf08-8592-413e-c186-59f34f267ca8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(set(tweets))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6543"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YF5A5oAge3Ec"
      },
      "source": [
        "# tweets_tokens = []\n",
        "# for tweet in tweets:\n",
        "#   tweet_tokens = tokenizer.tokenize(tweet)\n",
        "#   tweets_tokens.append(tweet_tokens)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y98gEM-xuoDu"
      },
      "source": [
        "tweets_tokens = []\n",
        "for tweet in set(tweets):\n",
        "  tweet_tokens = re.sub(' +', ' ',\n",
        "                        tweet.replace('\\n', ' ').\n",
        "                        replace('.', ' ').\n",
        "                        replace('،', ' ').\n",
        "                        replace('!', ' ').\n",
        "                        replace('?', ' ').\n",
        "                        replace(':', ' ').\n",
        "                        replace('؟', ' ').\n",
        "                        replace('_', ' ').\n",
        "                        replace('|', ' ').\n",
        "                        replace('/', ' ').\n",
        "                        replace('+', ' ').\n",
        "                        replace('[', ' ').\n",
        "                        replace(']', ' '))\n",
        "  tweet_tokens = parsivar_tokenizer.tokenize_words(parsivar_normalizer.normalize(tweet_tokens))\n",
        "  tweets_tokens.append(tweet_tokens)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JWHa4P0F97ss",
        "outputId": "51dcacd2-b64f-4099-d22d-48f01f7ed01d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "tweets_tokens[1]"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['تو',\n",
              " 'فرشته',\n",
              " 'الهیه',\n",
              " 'تو',\n",
              " 'صف',\n",
              " 'بکنی',\n",
              " 'چیز',\n",
              " 'بهت',\n",
              " 'نیمگن',\n",
              " 'بابا',\n",
              " '))',\n",
              " 'یهو',\n",
              " 'از',\n",
              " '100',\n",
              " 'می\\u200cتونی',\n",
              " 'بیای',\n",
              " '1',\n",
              " 'کدوم',\n",
              " 'سمتین',\n",
              " 'مگه',\n",
              " '))))']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5H-xsIRs5SoF",
        "outputId": "309293a7-2d13-45aa-eac5-1330951ae088",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "counter = 0\n",
        "with open('persian-ner-twitter-data.txt', 'w') as file:\n",
        "  for tweet_tokens in tweets_tokens:\n",
        "    for token in tweet_tokens:\n",
        "      if token != '':\n",
        "        counter += 1\n",
        "        file.write(token + '\\tO\\n')\n",
        "    file.write('\\n')\n",
        "print(counter)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "187405\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RKtKA_oK9YZq",
        "outputId": "c8cff11d-810d-48bf-bdbe-34ad3db4a45e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "! head -n 200 persian-ner-twitter-data.txt"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "تو\tO\n",
            "فرشته\tO\n",
            "الهیه\tO\n",
            "تو\tO\n",
            "صف\tO\n",
            "بکنی\tO\n",
            "چیز\tO\n",
            "بهت\tO\n",
            "نیمگن\tO\n",
            "بابا\tO\n",
            "))\tO\n",
            "یهو\tO\n",
            "از\tO\n",
            "100\tO\n",
            "می‌تونی\tO\n",
            "بیای\tO\n",
            "1\tO\n",
            "کدوم\tO\n",
            "سمتین\tO\n",
            "مگه\tO\n",
            "))))\tO\n",
            "\n",
            "چقدر\tO\n",
            "خوبست\tO\n",
            "که\tO\n",
            "حرف\tO\n",
            "حق\tO\n",
            "بزنیم\tO\n",
            "جالبست\tO\n",
            "ما\tO\n",
            "از\tO\n",
            "دروغ‌های\tO\n",
            "ج\tO\n",
            "ا\tO\n",
            "انتقاد\tO\n",
            "و\tO\n",
            "از\tO\n",
            "آن‌ها\tO\n",
            "ابراز\tO\n",
            "انزجار\tO\n",
            "می‌کنیم\tO\n",
            "اما\tO\n",
            "خودمان\tO\n",
            "مثل\tO\n",
            "آب\tO\n",
            "خوردن\tO\n",
            "دروغ\tO\n",
            "میگیم\tO\n",
            "و\tO\n",
            "به\tO\n",
            "دیگران\tO\n",
            "انگ\tO\n",
            "می‌زنیم\tO\n",
            "برای\tO\n",
            "مثال\tO\n",
            "نوری‌زاد\tO\n",
            "در\tO\n",
            "زندان\tO\n",
            "در\tO\n",
            "شرف\tO\n",
            "موت\tO\n",
            "است\tO\n",
            "اما\tO\n",
            "ما\tO\n",
            "اورا\tO\n",
            "مهره\tO\n",
            "ج\tO\n",
            "ا\tO\n",
            "مینامیم\tO\n",
            "آخر\tO\n",
            "وقتی\tO\n",
            "مرد\tO\n",
            "چه\tO\n",
            "پاداشی\tO\n",
            "را\tO\n",
            "می‌تواند\tO\n",
            "دریافت\tO\n",
            "کند\tO\n",
            "کمی\tO\n",
            "انصاف\tO\n",
            "\n",
            "فقط\tO\n",
            "موندم\tO\n",
            "چرا\tO\n",
            "جوادی\tO\n",
            "نشسته\tO\n",
            "داره\tO\n",
            "گوش\tO\n",
            "می‌ده\tO\n",
            "\n",
            "ایران\tO\n",
            "اینترنشنال\tO\n",
            "همین\tO\n",
            "چند\tO\n",
            "روز\tO\n",
            "پیش\tO\n",
            "یه\tO\n",
            "مستند\tO\n",
            "درباره\tO\n",
            "انتخابات\tO\n",
            "آمریکا\tO\n",
            "پخش\tO\n",
            "کرد\tO\n",
            "که\tO\n",
            "سری\tO\n",
            "هم\tO\n",
            "به\tO\n",
            "لاس‌وگاس\tO\n",
            "زد\tO\n",
            "و\tO\n",
            "به\tO\n",
            "یه\tO\n",
            "آموزشگاه\tO\n",
            "دیلری\tO\n",
            "رفت\tO\n",
            "مربی\tO\n",
            "و\tO\n",
            "صاحب\tO\n",
            "آموزشگاه\tO\n",
            "از\tO\n",
            "تاثیر\tO\n",
            "کرونا\tO\n",
            "رو\tO\n",
            "کسب\tO\n",
            "و\tO\n",
            "کارها\tO\n",
            "گفت\tO\n",
            "و\tO\n",
            "این\tO\n",
            "اعداد\tO\n",
            "رو\tO\n",
            "درباره\tO\n",
            "درآمد\tO\n",
            "و\tO\n",
            "دستمزد\tO\n",
            "دیلر‌ها\tO\n",
            "اون\tO\n",
            "ارائه\tO\n",
            "داد\tO\n",
            "گزارش\tO\n",
            "برای\tO\n",
            "یکهفته\tO\n",
            "پیشه\tO\n",
            "\n",
            "شهدای\tO\n",
            "مدافع\tO\n",
            "حرم\tO\n",
            "شهید\tO\n",
            "اینانلو\tO\n",
            "-\tO\n",
            "شهید\tO\n",
            "عباس\tO\n",
            "اسمیه\tO\n",
            "-\tO\n",
            "شهید\tO\n",
            "رضا\tO\n",
            "کارگر\tO\n",
            "برزی\tO\n",
            "-\tO\n",
            "شهید\tO\n",
            "مسیب\tO\n",
            "زاده\tO\n",
            "-\tO\n",
            "شهید\tO\n",
            "مهدی\tO\n",
            "عسکری\tO\n",
            "-\tO\n",
            "شهید\tO\n",
            "تمام\tO\n",
            "زاده\tO\n",
            "-\tO\n",
            "شهید\tO\n",
            "مهدی\tO\n",
            "نعمایی\tO\n",
            "-\tO\n",
            "شهید\tO\n",
            "نریمانی\tO\n",
            "-\tO\n",
            "و\tO\n",
            "شهدای\tO\n",
            "پاک\tO\n",
            "دیگر\tO\n",
            "معروف\tO\n",
            "به\tO\n",
            "قطب\tO\n",
            "علم\tO\n",
            "و\tO\n",
            "فناوری\tO\n",
            "ایران\tO\n",
            "-\tO\n",
            "قطب\tO\n",
            "تولید\tO\n",
            "میوه\tO\n",
            "باغی\tO\n",
            "ایران\tO\n",
            "-\tO\n",
            "ایران\tO\n",
            "کوچک\tO\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LdJu_tEFcdWo"
      },
      "source": [
        "# **Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BWIrxhBYU-_G"
      },
      "source": [
        "from transformers import pipeline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zcIkcJDTU_xw",
        "outputId": "f7ed8af3-60f8-44c3-9590-69c291f02be3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        }
      },
      "source": [
        "pars_ner = pipeline('ner', model=model, tokenizer=tokenizer)\n",
        "pars_ner(tweet_example)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'entity': 'B-organization',\n",
              "  'index': 8,\n",
              "  'score': 0.9995940327644348,\n",
              "  'word': 'اتلتیکو'},\n",
              " {'entity': 'B-organization',\n",
              "  'index': 13,\n",
              "  'score': 0.9972712397575378,\n",
              "  'word': 'بایرن'},\n",
              " {'entity': 'B-person',\n",
              "  'index': 31,\n",
              "  'score': 0.9915841817855835,\n",
              "  'word': 'هاینکس'}]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GNUWDyFhS3Y4"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}