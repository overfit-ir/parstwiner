{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tempo.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/overfit-ir/persian-twitter-ner/blob/master/tokenizer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rMbgFS_xcfcf"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nF-7m57sBgdp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "0c7f1826-f308-4023-ceda-0e3abe1f4253"
      },
      "source": [
        "! pip -q install transformers\n",
        "! pip -q install parsivar"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 1.1MB 6.6MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.1MB 22.5MB/s \n",
            "\u001b[K     |████████████████████████████████| 890kB 39.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.0MB 43.9MB/s \n",
            "\u001b[?25h  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[K     |████████████████████████████████| 36.2MB 82kB/s \n",
            "\u001b[K     |████████████████████████████████| 1.5MB 37.0MB/s \n",
            "\u001b[?25h  Building wheel for parsivar (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for nltk (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GbAOjVTbIvjW"
      },
      "source": [
        "import torch\n",
        "from __future__ import unicode_literals\n",
        "# from hazm import *\n",
        "from parsivar import *\n",
        "from pprint import pprint\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "from scipy import spatial\n",
        "from transformers import AutoConfig, AutoTokenizer, AutoModel, AutoModelForTokenClassification\n",
        "import re\n",
        "parsivar_tokenizer = Tokenizer()\n",
        "parsivar_normalizer = Normalizer(statistical_space_correction=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZZAJwNKuIwLN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2f7371dd-d346-47c7-82e3-5dfac6d47f8e"
      },
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"m3hrdadfi/albert-fa-base-v2-ner\")\n",
        "# tokenizer = AutoTokenizer.from_pretrained(\"HooshvareLab/bert-base-parsbert-ner-uncased\")\n",
        "model = AutoModelForTokenClassification.from_pretrained(\"m3hrdadfi/albert-fa-base-v2-ner\")\n",
        "model.eval()\n",
        "print()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h_5tgmwqch8n"
      },
      "source": [
        "# **Tokenize**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CmwTpkbxdEGv"
      },
      "source": [
        "### Tokenize All tweets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "naQ5Dy8tdN4M",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "eaafc7f9-3a4f-4335-914e-af5d498272c6"
      },
      "source": [
        "! wget \"https://raw.githubusercontent.com/overfit-ir/persian-twitter-ner/master/twitter_data/extracted_data.txt\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-10-19 09:23:19--  https://raw.githubusercontent.com/overfit-ir/persian-twitter-ner/master/twitter_data/extracted_data.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2698436 (2.6M) [text/plain]\n",
            "Saving to: ‘extracted_data.txt.1’\n",
            "\n",
            "extracted_data.txt. 100%[===================>]   2.57M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2020-10-19 09:23:19 (20.9 MB/s) - ‘extracted_data.txt.1’ saved [2698436/2698436]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ky_SVWj-d9K5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "8d9f32cc-2802-405c-c520-6a427204b59c"
      },
      "source": [
        "tweets_str = \"\"\n",
        "with open(\"extracted_data.txt\") as file:\n",
        "  for line in file.readlines():\n",
        "    tweets_str += line\n",
        "tweets_str[:20]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'خرداد ۱۳۹۹ «کیهان» م'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pqt4gc0LeiY7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "57eeed96-707d-41fd-814b-023dd737eaa4"
      },
      "source": [
        "tweets = tweets_str.split(\"\\n\\n**************\\n\\n\")\n",
        "tweets[0], len(tweets)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('خرداد ۱۳۹۹ «کیهان» میراث سناتور مصطفی مصباح\\u200cزاده ۷۸ ساله شد \\nکیهان لندن تنها رسانه\\u200c ایرانی در تبعید است که «از جنگ دوم جهانی تاکنون قدمت و یک مؤسسه\\u200c غصب \\u200cشده در تهران» دارد.\\n\\n',\n",
              " 9349)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FyTcsd452GaG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b1816a61-1741-4c6c-d417-2b2f3f596585"
      },
      "source": [
        "len(tweets)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9349"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PvVwD5co44yA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6507ee9d-9c2d-4071-eddd-35abd5fe5535"
      },
      "source": [
        "len(set(tweets))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9349"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y98gEM-xuoDu"
      },
      "source": [
        "tweets_tokens = []\n",
        "for tweet in tweets:\n",
        "  tweet_tokens = re.sub('[.]+[ ]?[.]+', '.', re.sub(' +', ' ',\n",
        "                                    tweet.replace('_', ' ').\n",
        "                                    replace('|', ' ').\n",
        "                                    replace('/', ' ').\n",
        "                                    replace('+', ' ').\n",
        "                                    replace('[', ' ').\n",
        "                                    replace(']', ' ')))\n",
        "  tweet_tokens = parsivar_tokenizer.tokenize_words(parsivar_normalizer.normalize(tweet_tokens))\n",
        "  tweets_tokens.append(tweet_tokens)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JWHa4P0F97ss",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 680
        },
        "outputId": "b508688f-4408-4599-a54a-52347349e3bd"
      },
      "source": [
        "tweets_tokens[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['خرداد',\n",
              " '1399',\n",
              " '«',\n",
              " 'کیهان',\n",
              " '»',\n",
              " 'میراث',\n",
              " 'سناتور',\n",
              " 'مصطفی',\n",
              " 'مصباح\\u200cزاده',\n",
              " '78',\n",
              " 'ساله',\n",
              " 'شد',\n",
              " '.',\n",
              " 'کیهان',\n",
              " 'لندن',\n",
              " 'تنها',\n",
              " 'رسانه',\n",
              " 'ایرانی',\n",
              " 'در',\n",
              " 'تبعید',\n",
              " 'است',\n",
              " 'که',\n",
              " '«',\n",
              " 'از',\n",
              " 'جنگ',\n",
              " 'دوم',\n",
              " 'جهانی',\n",
              " 'تاکنون',\n",
              " 'قدمت',\n",
              " 'و',\n",
              " 'یک',\n",
              " 'موسسه',\n",
              " 'غصب',\n",
              " 'شده',\n",
              " 'در',\n",
              " 'تهران',\n",
              " '»',\n",
              " 'دارد',\n",
              " '.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5H-xsIRs5SoF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e9c4272a-2429-47b1-84e3-22204f7386de"
      },
      "source": [
        "counter = 0\n",
        "for i in range(1, 11):\n",
        "  with open('persian-ner-twitter-data' + str(i) + '.txt', 'w') as file:\n",
        "    if i != 10:\n",
        "      bin = tweets_tokens[(i-1)*1000:i*1000]\n",
        "    else:\n",
        "      bin = tweets_tokens[(i-1)*1000:len(tweets_tokens)]\n",
        "    for tweet_tokens in bin:\n",
        "      for token in tweet_tokens:\n",
        "        if token != '':\n",
        "          counter += 1\n",
        "          file.write(token + '\\tO\\n')\n",
        "      file.write('\\n')\n",
        "print(counter)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "276026\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RKtKA_oK9YZq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 867
        },
        "outputId": "b842ac9e-9e21-4bf5-90f7-a9ad449db638"
      },
      "source": [
        "! head -n 50 persian-ner-twitter-data1.txt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "خرداد\tO\n",
            "1399\tO\n",
            "«\tO\n",
            "کیهان\tO\n",
            "»\tO\n",
            "میراث\tO\n",
            "سناتور\tO\n",
            "مصطفی\tO\n",
            "مصباح‌زاده\tO\n",
            "78\tO\n",
            "ساله\tO\n",
            "شد\tO\n",
            ".\tO\n",
            "کیهان\tO\n",
            "لندن\tO\n",
            "تنها\tO\n",
            "رسانه\tO\n",
            "ایرانی\tO\n",
            "در\tO\n",
            "تبعید\tO\n",
            "است\tO\n",
            "که\tO\n",
            "«\tO\n",
            "از\tO\n",
            "جنگ\tO\n",
            "دوم\tO\n",
            "جهانی\tO\n",
            "تاکنون\tO\n",
            "قدمت\tO\n",
            "و\tO\n",
            "یک\tO\n",
            "موسسه\tO\n",
            "غصب\tO\n",
            "شده\tO\n",
            "در\tO\n",
            "تهران\tO\n",
            "»\tO\n",
            "دارد\tO\n",
            ".\tO\n",
            "\n",
            "چهارمین\tO\n",
            "قهرمانی\tO\n",
            "فلومیننسه\tO\n",
            "در\tO\n",
            "برزیل\tO\n",
            ":\tO\n",
            "\n",
            "زندگی\tO\n",
            "سلام\tO\n",
            ".\tO\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LdJu_tEFcdWo"
      },
      "source": [
        "# **Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BWIrxhBYU-_G"
      },
      "source": [
        "from transformers import pipeline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zcIkcJDTU_xw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        },
        "outputId": "f7ed8af3-60f8-44c3-9590-69c291f02be3"
      },
      "source": [
        "pars_ner = pipeline('ner', model=model, tokenizer=tokenizer)\n",
        "pars_ner(tweet_example)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'entity': 'B-organization',\n",
              "  'index': 8,\n",
              "  'score': 0.9995940327644348,\n",
              "  'word': 'اتلتیکو'},\n",
              " {'entity': 'B-organization',\n",
              "  'index': 13,\n",
              "  'score': 0.9972712397575378,\n",
              "  'word': 'بایرن'},\n",
              " {'entity': 'B-person',\n",
              "  'index': 31,\n",
              "  'score': 0.9915841817855835,\n",
              "  'word': 'هاینکس'}]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GNUWDyFhS3Y4"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}