{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tempo.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/overfit-ir/persian-twitter-ner/blob/master/ner-survey-models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ebZsy7HYObGg"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hWNzPQINXSE1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25e180d7-6dee-4ca2-f940-fb18adb114fd"
      },
      "source": [
        "!pip -q install transformers\n",
        "!pip  -q install sentencepiece"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 1.8MB 8.5MB/s \n",
            "\u001b[K     |████████████████████████████████| 2.9MB 50.5MB/s \n",
            "\u001b[K     |████████████████████████████████| 890kB 50.6MB/s \n",
            "\u001b[?25h  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[K     |████████████████████████████████| 1.2MB 6.7MB/s \n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nF-7m57sBgdp"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from transformers import (\n",
        "    pipeline, \n",
        "    AutoConfig, \n",
        "    AutoTokenizer, \n",
        "    AutoModel, \n",
        "    AutoModelForTokenClassification\n",
        ")"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fzRbmIoZOvs5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0b9bb8b-2743-4f29-bad2-ec1bdda188c3"
      },
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"m3hrdadfi/albert-fa-base-v2-ner\")\n",
        "model = AutoModelForTokenClassification.from_pretrained(\"m3hrdadfi/albert-fa-base-v2-ner\")\n",
        "model.eval()\n",
        "print()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M1Awb1uBEExX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c6c0bdab-7a30-4aea-e360-6c2558a34503"
      },
      "source": [
        "!wget -q --show-progress 'https://raw.githubusercontent.com/overfit-ir/persian-twitter-ner/master/twitter_data/persian-ner-twitter-data/persian-ner-twitter-data1.txt'\n",
        "!wget -q --show-progress 'https://raw.githubusercontent.com/overfit-ir/persian-twitter-ner/master/twitter_data/persian-ner-twitter-data/persian-ner-twitter-data2.txt'\n",
        "!wget -q --show-progress 'https://raw.githubusercontent.com/overfit-ir/persian-twitter-ner/master/twitter_data/persian-ner-twitter-data/persian-ner-twitter-data3.txt'\n",
        "!wget -q --show-progress 'https://raw.githubusercontent.com/overfit-ir/persian-twitter-ner/master/twitter_data/persian-ner-twitter-data/persian-ner-twitter-data4.txt'\n",
        "!wget -q --show-progress 'https://raw.githubusercontent.com/overfit-ir/persian-twitter-ner/master/twitter_data/persian-ner-twitter-data/persian-ner-twitter-data5.txt'\n",
        "!wget -q --show-progress 'https://raw.githubusercontent.com/overfit-ir/persian-twitter-ner/master/twitter_data/persian-ner-twitter-data/persian-ner-twitter-data6.txt'\n",
        "!wget -q --show-progress 'https://raw.githubusercontent.com/overfit-ir/persian-twitter-ner/master/twitter_data/persian-ner-twitter-data/persian-ner-twitter-data7.txt'\n",
        "!wget -q --show-progress 'https://raw.githubusercontent.com/overfit-ir/persian-twitter-ner/master/twitter_data/persian-ner-twitter-data/persian-ner-twitter-data8.txt'\n",
        "!wget -q --show-progress 'https://raw.githubusercontent.com/overfit-ir/persian-twitter-ner/master/twitter_data/persian-ner-twitter-data/persian-ner-twitter-data9.txt'\n",
        "!wget -q --show-progress 'https://raw.githubusercontent.com/overfit-ir/persian-twitter-ner/master/twitter_data/persian-ner-twitter-data/persian-ner-twitter-data10.txt'\n",
        "!mkdir data && mv persian-ner* data/"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "persian-ner-twitter 100%[===================>] 276.22K  --.-KB/s    in 0.03s   \n",
            "persian-ner-twitter 100%[===================>] 245.49K  --.-KB/s    in 0.02s   \n",
            "persian-ner-twitter 100%[===================>] 308.37K  --.-KB/s    in 0.02s   \n",
            "persian-ner-twitter 100%[===================>] 226.92K  --.-KB/s    in 0.02s   \n",
            "persian-ner-twitter 100%[===================>] 296.98K  --.-KB/s    in 0.03s   \n",
            "persian-ner-twitter 100%[===================>] 217.98K  --.-KB/s    in 0.02s   \n",
            "persian-ner-twitter 100%[===================>] 287.11K  --.-KB/s    in 0.02s   \n",
            "persian-ner-twitter 100%[===================>] 263.38K  --.-KB/s    in 0.02s   \n",
            "persian-ner-twitter 100%[===================>] 298.05K  --.-KB/s    in 0.02s   \n",
            "persian-ner-twitter 100%[===================>] 103.19K  --.-KB/s    in 0.01s   \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D6_zKUcGOlCU"
      },
      "source": [
        "# Convert to Text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qJtW5DROJJSl"
      },
      "source": [
        "from pathlib import Path\n",
        "import re\n",
        "\n",
        "def convert_lines_to_text(file_path):\n",
        "    file_path = Path(file_path)\n",
        "\n",
        "    raw_text = file_path.read_text().strip()\n",
        "    raw_docs = re.split(r'\\n\\t?\\n', raw_text)\n",
        "    token_docs = []\n",
        "    tag_docs = []\n",
        "    for doc in raw_docs:\n",
        "        tokens = []\n",
        "        tags = []\n",
        "        for line in doc.split('\\n'):\n",
        "            token, tag = line.split('\\t')\n",
        "            tokens.append(token)\n",
        "            tags.append(tag)\n",
        "        token_docs.append(tokens)\n",
        "        tag_docs.append(tags)\n",
        "\n",
        "    return token_docs, tag_docs"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i9Q5H5PXOqf7"
      },
      "source": [
        "texts, tags = convert_lines_to_text('data/persian-ner-twitter-data1.txt')"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z5rW0BgOQ5QS",
        "outputId": "2cfc5d95-997b-493f-d392-e4be9c46e780"
      },
      "source": [
        "print(texts[0])\n",
        "print(tags[0])"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['خرداد', '1399', '«', 'کیهان', '»', 'میراث', 'سناتور', 'مصطفی', 'مصباح\\u200cزاده', '78', 'ساله', 'شد', 'کیهان', 'لندن', 'تنها', 'رسانه', 'ایرانی', 'در', 'تبعید', 'است', 'که', '«', 'از', 'جنگ', 'دوم', 'جهانی', 'تاکنون', 'قدمت', 'و', 'یک', 'موسسه', 'غصب', 'شده', 'در', 'تهران', '»', 'دارد']\n",
            "['O', 'O', 'O', 'B-ORG', 'O', 'O', 'O', 'B-PER', 'I-PER', 'O', 'O', 'O', 'B-ORG', 'B-LOC', 'O', 'O', 'B-NAT', 'O', 'O', 'O', 'O', 'O', 'O', 'B-EVE', 'I-EVE', 'I-EVE', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'O', 'O']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "HYPvTHz3Ub1D",
        "outputId": "93b23f59-8c21-4b71-841e-e2b6b24b9a7a"
      },
      "source": [
        "s = ''\n",
        "for word in texts[0]:\n",
        "  s += word + ' '\n",
        "s"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'خرداد 1399 « کیهان » میراث سناتور مصطفی مصباح\\u200cزاده 78 ساله شد کیهان لندن تنها رسانه ایرانی در تبعید است که « از جنگ دوم جهانی تاکنون قدمت و یک موسسه غصب شده در تهران » دارد '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ksa__4JhVKNI",
        "outputId": "2e680868-9171-4620-ed0f-b21904635f48"
      },
      "source": [
        "tokenizer.tokenize(s)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['▁خرداد',\n",
              " '▁',\n",
              " '1399',\n",
              " '▁',\n",
              " '«',\n",
              " '▁کیهان',\n",
              " '▁',\n",
              " '»',\n",
              " '▁میراث',\n",
              " '▁سناتور',\n",
              " '▁مصطفی',\n",
              " '▁مصباح',\n",
              " '▁زاده',\n",
              " '▁',\n",
              " '78',\n",
              " '▁ساله',\n",
              " '▁شد',\n",
              " '▁کیهان',\n",
              " '▁لندن',\n",
              " '▁تنها',\n",
              " '▁رسانه',\n",
              " '▁ایرانی',\n",
              " '▁در',\n",
              " '▁تبعید',\n",
              " '▁است',\n",
              " '▁که',\n",
              " '▁',\n",
              " '«',\n",
              " '▁از',\n",
              " '▁جنگ',\n",
              " '▁دوم',\n",
              " '▁جهانی',\n",
              " '▁تاکنون',\n",
              " '▁قدمت',\n",
              " '▁و',\n",
              " '▁یک',\n",
              " '▁موسسه',\n",
              " '▁غصب',\n",
              " '▁شده',\n",
              " '▁در',\n",
              " '▁تهران',\n",
              " '▁',\n",
              " '»',\n",
              " '▁دارد']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RTg7QMrgOzh0"
      },
      "source": [
        "# Benchmark"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cNoJRziHaqEx"
      },
      "source": [
        "albert_ner = pipeline('ner', model=model, tokenizer=tokenizer)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-F-7yXR1PYnV",
        "outputId": "bc945e21-112e-4de4-89cc-fb4fa1e19376",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "albert_ner(s)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'end': 18,\n",
              "  'entity': 'B-organization',\n",
              "  'index': 6,\n",
              "  'score': 0.6452239155769348,\n",
              "  'start': 13,\n",
              "  'word': '▁کیهان'},\n",
              " {'end': 39,\n",
              "  'entity': 'B-person',\n",
              "  'index': 11,\n",
              "  'score': 0.9977455139160156,\n",
              "  'start': 34,\n",
              "  'word': '▁مصطفی'},\n",
              " {'end': 45,\n",
              "  'entity': 'I-person',\n",
              "  'index': 12,\n",
              "  'score': 0.9973155856132507,\n",
              "  'start': 40,\n",
              "  'word': '▁مصباح'},\n",
              " {'end': 50,\n",
              "  'entity': 'I-person',\n",
              "  'index': 13,\n",
              "  'score': 0.8139748573303223,\n",
              "  'start': 46,\n",
              "  'word': '▁زاده'},\n",
              " {'end': 67,\n",
              "  'entity': 'B-organization',\n",
              "  'index': 18,\n",
              "  'score': 0.8885950446128845,\n",
              "  'start': 62,\n",
              "  'word': '▁کیهان'},\n",
              " {'end': 72,\n",
              "  'entity': 'I-organization',\n",
              "  'index': 19,\n",
              "  'score': 0.8778548240661621,\n",
              "  'start': 68,\n",
              "  'word': '▁لندن'},\n",
              " {'end': 165,\n",
              "  'entity': 'B-location',\n",
              "  'index': 41,\n",
              "  'score': 0.9980483055114746,\n",
              "  'start': 160,\n",
              "  'word': '▁تهران'}]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YuuoB7sxjk0Y"
      },
      "source": [
        "# Benchmark2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y0dGPIj5MTqW"
      },
      "source": [
        "!cat data/dev.txt.tmp | grep -v \"^#\" | cut -f 2,3 | tr '\\t' ' ' > dev.txt.tmp\n",
        "# !cat NER-de-dev.tsv | grep -v \"^#\" | cut -f 2,3 | tr '\\t' ' ' > dev.txt.tmp\n",
        "# !cat NER-de-test.tsv | grep -v \"^#\" | cut -f 2,3 | tr '\\t' ' ' > test.txt.tmp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ui3HZfRwfwTH"
      },
      "source": [
        "!git clone https://github.com/huggingface/transformers\n",
        "!pip install transformers/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bRDjXWaqgDLv"
      },
      "source": [
        "!pip install sentencepiece"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Atfg8k8Ajqv-"
      },
      "source": [
        "!wget \"https://raw.githubusercontent.com/stefan-it/fine-tuned-berts-seq/master/scripts/preprocess.py\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "itWy78SnkBlk"
      },
      "source": [
        "# !python3 preprocess.py train.txt.tmp HooshvareLab/bert-base-parsbert-uncased 128 > train.txt\n",
        "!python3 preprocess.py dev.txt.tmp HooshvareLab/bert-base-parsbert-uncased 128 > dev.txt\n",
        "# !python3 preprocess.py test.txt.tmp m3hrdadfi/albert-fa-base-v2-ner 128 > test.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vdHj8GTrlBnr"
      },
      "source": [
        "!pip install -r transformers/examples/token-classification/requirements.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rgZbOD--k4LN"
      },
      "source": [
        "!mv dev.txt data/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iw_LDa1JpOcf"
      },
      "source": [
        "!cat data/dev.txt | cut -d \" \" -f 2 | grep -v \"^$\"| sort | uniq > labels.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oQKW9EiUlYVk"
      },
      "source": [
        "!python3 transformers/examples/legacy/token-classification/run_ner.py --data_dir data/ \\\n",
        "--labels labels.txt \\\n",
        "--model_name_or_path HooshvareLab/bert-base-parsbert-uncased \\\n",
        "--output_dir eval/ \\\n",
        "--max_seq_length  128 \\\n",
        "--save_steps 750 \\\n",
        "--seed 1 \\\n",
        "--do_eval"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xjsEn3v9lZmL"
      },
      "source": [
        "!pip install conllu"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sAkK4ULyufrL"
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_kXaI2a3uiNI"
      },
      "source": [
        "with open('data-fa/train.csv', 'r+') as file:\n",
        "  s = ''\n",
        "  for line in file.readlines():\n",
        "    s += line.replace(',', '\\t')\n",
        "  file.seek = 0\n",
        "  file.write(s)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YJfJyM85w5e8"
      },
      "source": [
        "!cat data-fa/train.csv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pwLISJ6EnbdW"
      },
      "source": [
        "!curl -L 'https://drive.google.com/file/d/1Jjhbal535VVz2ap4v4r_rN1UEHTdLK5P/view?usp=sharing' \\\n",
        "| grep -v \"^#\" | cut -f 2,3 | tr '\\t' ' ' > train.txt.tmp\n",
        "!curl -L 'https://drive.google.com/file/d/1ZfRcQThdtAR5PPRjIDtrVP7BtXSCUBbm/view?usp=sharing' \\\n",
        "| grep -v \"^#\" | cut -f 2,3 | tr '\\t' ' ' > dev.txt.tmp\n",
        "!curl -L 'https://drive.google.com/file/d/1u9mb7kNJHWQCWyweMDRMuTFoOHOfeBTH/view?usp=sharing' \\\n",
        "| grep -v \"^#\" | cut -f 2,3 | tr '\\t' ' ' > test.txt.tmp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VsXoweocoGFr"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}