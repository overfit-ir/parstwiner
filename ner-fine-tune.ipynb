{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tempo.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/overfit-ir/persian-twitter-ner/blob/master/ner-fine-tune.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ebZsy7HYObGg"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nF-7m57sBgdp"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M1Awb1uBEExX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "236569cb-6138-424a-c050-38144f2599c7"
      },
      "source": [
        "!wget -q --show-progress 'https://raw.githubusercontent.com/overfit-ir/persian-twitter-ner/master/twitter_data/persian-ner-twitter-data/train.txt'\n",
        "!wget -q --show-progress 'https://raw.githubusercontent.com/overfit-ir/persian-twitter-ner/master/twitter_data/persian-ner-twitter-data/test.txt'\n",
        "!mkdir data && mv train.txt data && mv test.txt data"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train.txt           100%[===================>]   2.22M  --.-KB/s    in 0.06s   \n",
            "test.txt            100%[===================>] 245.46K  --.-KB/s    in 0.02s   \n",
            "mkdir: cannot create directory ‘data’: File exists\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YuuoB7sxjk0Y"
      },
      "source": [
        "# Benchmark2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y0dGPIj5MTqW"
      },
      "source": [
        "!cat data/train.txt | grep -v \"^#\" | cut -f 1,2 | tr '\\t' ' ' > train.txt.tmp\n",
        "!cat data/test.txt | grep -v \"^#\" | cut -f 1,2 | tr '\\t' ' ' > test.txt.tmp"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ui3HZfRwfwTH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "151e1f0c-135d-477b-da4b-e0ba2dad11ee"
      },
      "source": [
        "!git clone https://github.com/huggingface/transformers\n",
        "!pip install transformers/\n",
        "!pip install sentencepiece"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'transformers'...\n",
            "remote: Enumerating objects: 71, done.\u001b[K\n",
            "remote: Counting objects: 100% (71/71), done.\u001b[K\n",
            "remote: Compressing objects: 100% (50/50), done.\u001b[K\n",
            "remote: Total 60794 (delta 27), reused 49 (delta 15), pack-reused 60723\u001b[K\n",
            "Receiving objects: 100% (60794/60794), 45.62 MiB | 24.96 MiB/s, done.\n",
            "Resolving deltas: 100% (42914/42914), done.\n",
            "Processing ./transformers\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers==4.3.0.dev0) (2019.12.20)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 8.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers==4.3.0.dev0) (3.0.12)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers==4.3.0.dev0) (4.41.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers==4.3.0.dev0) (20.8)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers==4.3.0.dev0) (2.23.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from transformers==4.3.0.dev0) (3.3.0)\n",
            "Collecting tokenizers==0.9.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0f/1c/e789a8b12e28be5bc1ce2156cf87cb522b379be9cadc7ad8091a4cc107c4/tokenizers-0.9.4-cp36-cp36m-manylinux2010_x86_64.whl (2.9MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9MB 7.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers==4.3.0.dev0) (1.19.5)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers==4.3.0.dev0) (0.8)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==4.3.0.dev0) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==4.3.0.dev0) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==4.3.0.dev0) (1.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers==4.3.0.dev0) (2.4.7)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==4.3.0.dev0) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==4.3.0.dev0) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==4.3.0.dev0) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==4.3.0.dev0) (1.24.3)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers==4.3.0.dev0) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers==4.3.0.dev0) (3.4.0)\n",
            "Building wheels for collected packages: transformers\n",
            "  Building wheel for transformers (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for transformers: filename=transformers-4.3.0.dev0-cp36-none-any.whl size=1783249 sha256=bbe4e984b398d3739016ee7295c04953dc0c0609fa9c7c181a5b0330c2bd99e1\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-jizfjd_7/wheels/23/19/dd/2561a4e47240cf6b307729d58e56f8077dd0c698f5992216cf\n",
            "Successfully built transformers\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893261 sha256=40e30d7ffa6dc43daafbbca783278143c03d2967bb8f8acb98f42bdddee845cc\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sacremoses, tokenizers, transformers\n",
            "Successfully installed sacremoses-0.0.43 tokenizers-0.9.4 transformers-4.3.0.dev0\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/67/e42bd1181472c95c8cda79305df848264f2a7f62740995a46945d9797b67/sentencepiece-0.1.95-cp36-cp36m-manylinux2014_x86_64.whl (1.2MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2MB 8.4MB/s \n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.95\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Atfg8k8Ajqv-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "37297f26-d174-4ebb-8352-b51011d70505"
      },
      "source": [
        "!wget \"https://raw.githubusercontent.com/stefan-it/fine-tuned-berts-seq/master/scripts/preprocess.py\""
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-01-27 16:31:22--  https://raw.githubusercontent.com/stefan-it/fine-tuned-berts-seq/master/scripts/preprocess.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 991 [text/plain]\n",
            "Saving to: ‘preprocess.py’\n",
            "\n",
            "preprocess.py       100%[===================>]     991  --.-KB/s    in 0s      \n",
            "\n",
            "2021-01-27 16:31:22 (52.7 MB/s) - ‘preprocess.py’ saved [991/991]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "itWy78SnkBlk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc14b3f6-bb11-4a3f-a7e4-2465515a181a"
      },
      "source": [
        "# !python3 preprocess.py train.txt.tmp HooshvareLab/bert-base-parsbert-uncased 128 > train.txt\n",
        "!python3 preprocess.py train.txt.tmp HooshvareLab/bert-base-parsbert-uncased 128 > train.txt\n",
        "!python3 preprocess.py test.txt.tmp HooshvareLab/bert-base-parsbert-uncased 128 > test.txt"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: 100% 434/434 [00:00<00:00, 298kB/s]\n",
            "Downloading: 100% 1.22M/1.22M [00:00<00:00, 3.16MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vdHj8GTrlBnr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f90be94c-fcb8-486c-a349-fa389e86a83b"
      },
      "source": [
        "!pip install -r transformers/examples/token-classification/requirements.txt"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting seqeval\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9d/2d/233c79d5b4e5ab1dbf111242299153f3caddddbb691219f363ad55ce783d/seqeval-1.2.2.tar.gz (43kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 3.9MB/s \n",
            "\u001b[?25hCollecting datasets>=1.1.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/06/9b/d097f2238fc3c028495cf5f8c65378972b9f1b2cbb27f3c57c7219195aa9/datasets-1.2.1-py3-none-any.whl (159kB)\n",
            "\u001b[K     |████████████████████████████████| 163kB 12.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from seqeval->-r transformers/examples/token-classification/requirements.txt (line 1)) (1.19.5)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.6/dist-packages (from seqeval->-r transformers/examples/token-classification/requirements.txt (line 1)) (0.22.2.post1)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from datasets>=1.1.3->-r transformers/examples/token-classification/requirements.txt (line 2)) (3.3.0)\n",
            "Collecting pyarrow>=0.17.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/33/67/2f4fcce1b41bcc7e88a6bfdb42046597ae72e5bc95c2789b7c5ac893c433/pyarrow-3.0.0-cp36-cp36m-manylinux2014_x86_64.whl (20.7MB)\n",
            "\u001b[K     |████████████████████████████████| 20.7MB 7.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm<4.50.0,>=4.27 in /usr/local/lib/python3.6/dist-packages (from datasets>=1.1.3->-r transformers/examples/token-classification/requirements.txt (line 2)) (4.41.1)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.6/dist-packages (from datasets>=1.1.3->-r transformers/examples/token-classification/requirements.txt (line 2)) (2.23.0)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.6/dist-packages (from datasets>=1.1.3->-r transformers/examples/token-classification/requirements.txt (line 2)) (0.3.3)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from datasets>=1.1.3->-r transformers/examples/token-classification/requirements.txt (line 2)) (0.8)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.6/dist-packages (from datasets>=1.1.3->-r transformers/examples/token-classification/requirements.txt (line 2)) (0.70.11.1)\n",
            "Collecting xxhash\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f7/73/826b19f3594756cb1c6c23d2fbd8ca6a77a9cd3b650c9dec5acc85004c38/xxhash-2.0.0-cp36-cp36m-manylinux2010_x86_64.whl (242kB)\n",
            "\u001b[K     |████████████████████████████████| 245kB 43.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from datasets>=1.1.3->-r transformers/examples/token-classification/requirements.txt (line 2)) (1.1.5)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.21.3->seqeval->-r transformers/examples/token-classification/requirements.txt (line 1)) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.21.3->seqeval->-r transformers/examples/token-classification/requirements.txt (line 1)) (1.0.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->datasets>=1.1.3->-r transformers/examples/token-classification/requirements.txt (line 2)) (3.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->datasets>=1.1.3->-r transformers/examples/token-classification/requirements.txt (line 2)) (3.7.4.3)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->datasets>=1.1.3->-r transformers/examples/token-classification/requirements.txt (line 2)) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->datasets>=1.1.3->-r transformers/examples/token-classification/requirements.txt (line 2)) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->datasets>=1.1.3->-r transformers/examples/token-classification/requirements.txt (line 2)) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->datasets>=1.1.3->-r transformers/examples/token-classification/requirements.txt (line 2)) (2020.12.5)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->datasets>=1.1.3->-r transformers/examples/token-classification/requirements.txt (line 2)) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas->datasets>=1.1.3->-r transformers/examples/token-classification/requirements.txt (line 2)) (2.8.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.7.3->pandas->datasets>=1.1.3->-r transformers/examples/token-classification/requirements.txt (line 2)) (1.15.0)\n",
            "Building wheels for collected packages: seqeval\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-cp36-none-any.whl size=16171 sha256=3ceecc13602768847ae6d21713e844b94ffa7025a38179c259963ca0a665e214\n",
            "  Stored in directory: /root/.cache/pip/wheels/52/df/1b/45d75646c37428f7e626214704a0e35bd3cfc32eda37e59e5f\n",
            "Successfully built seqeval\n",
            "Installing collected packages: seqeval, pyarrow, xxhash, datasets\n",
            "  Found existing installation: pyarrow 0.14.1\n",
            "    Uninstalling pyarrow-0.14.1:\n",
            "      Successfully uninstalled pyarrow-0.14.1\n",
            "Successfully installed datasets-1.2.1 pyarrow-3.0.0 seqeval-1.2.2 xxhash-2.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rgZbOD--k4LN"
      },
      "source": [
        "!mkdir processed_data\n",
        "!mv train.txt processed_data/ && mv test.txt processed_data/"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iw_LDa1JpOcf"
      },
      "source": [
        "!cat processed_data/train.txt processed_data/test.txt | cut -d \" \" -f 2 | grep -v \"^$\"| sort | uniq > labels.txt"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oQKW9EiUlYVk"
      },
      "source": [
        "!python3 transformers/examples/legacy/token-classification/run_ner.py --data_dir data/ \\\n",
        "--labels labels.txt \\\n",
        "--model_name_or_path HooshvareLab/bert-base-parsbert-uncased \\\n",
        "--output_dir eval/ \\\n",
        "--max_seq_length  128 \\\n",
        "--save_steps 750 \\\n",
        "--seed 1 \\\n",
        "--do_eval"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xjsEn3v9lZmL"
      },
      "source": [
        "!pip install conllu"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sAkK4ULyufrL"
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_kXaI2a3uiNI"
      },
      "source": [
        "with open('data-fa/train.csv', 'r+') as file:\n",
        "  s = ''\n",
        "  for line in file.readlines():\n",
        "    s += line.replace(',', '\\t')\n",
        "  file.seek = 0\n",
        "  file.write(s)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YJfJyM85w5e8"
      },
      "source": [
        "!cat data-fa/train.csv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pwLISJ6EnbdW"
      },
      "source": [
        "!curl -L 'https://drive.google.com/file/d/1Jjhbal535VVz2ap4v4r_rN1UEHTdLK5P/view?usp=sharing' \\\n",
        "| grep -v \"^#\" | cut -f 2,3 | tr '\\t' ' ' > train.txt.tmp\n",
        "!curl -L 'https://drive.google.com/file/d/1ZfRcQThdtAR5PPRjIDtrVP7BtXSCUBbm/view?usp=sharing' \\\n",
        "| grep -v \"^#\" | cut -f 2,3 | tr '\\t' ' ' > dev.txt.tmp\n",
        "!curl -L 'https://drive.google.com/file/d/1u9mb7kNJHWQCWyweMDRMuTFoOHOfeBTH/view?usp=sharing' \\\n",
        "| grep -v \"^#\" | cut -f 2,3 | tr '\\t' ' ' > test.txt.tmp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VsXoweocoGFr"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}