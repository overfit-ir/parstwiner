{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "multi-task-training.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "OcqvEZ-r9frk"
      ],
      "toc_visible": true,
      "mount_file_id": "https://github.com/overfit-ir/persian-twitter-ner/blob/feature%2Fadd-multi-task-learning/multi_task_training.ipynb",
      "authorship_tag": "ABX9TyO+XVEKRD42sLa7pnq4BMHz",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/overfit-ir/persian-twitter-ner/blob/feature%2Fadd-multi-task-learning/multi_task_training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f52ONvc7LYvF",
        "outputId": "4a113756-50c6-44cc-ec83-a0324d71fd78",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G_MLN4DQ8cJc"
      },
      "source": [
        "### Get Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pLJ97FgG9UvT",
        "outputId": "5776b892-97be-4403-af64-7be21dda7ef1"
      },
      "source": [
        "!rm run_tf_ner.py tasks.py utils_ner.py"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rm: cannot remove 'run_tf_ner.py': No such file or directory\n",
            "rm: cannot remove 'tasks.py': No such file or directory\n",
            "rm: cannot remove 'utils_ner.py': No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "khyezUc9JFlE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d049d113-a8d8-46ce-c870-f2c29b37c689"
      },
      "source": [
        "!wget -q --show-progress --no-cache https://raw.githubusercontent.com/overfit-ir/persian-twitter-ner/feature/add-multi-task-learning/run_tf_ner.py\n",
        "!wget -q --show-progress --no-cache https://raw.githubusercontent.com/overfit-ir/persian-twitter-ner/feature/add-multi-task-learning/tasks.py\n",
        "!wget -q --show-progress --no-cache https://raw.githubusercontent.com/overfit-ir/persian-twitter-ner/feature/add-multi-task-learning/utils_ner.py"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "run_tf_ner.py       100%[===================>]  15.16K  --.-KB/s    in 0s      \n",
            "tasks.py            100%[===================>]   5.38K  --.-KB/s    in 0s      \n",
            "utils_ner.py        100%[===================>]  34.07K  --.-KB/s    in 0s      \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P7sVoYZR6okv",
        "outputId": "efe890e8-291a-494d-b94c-b09ee52db0d6"
      },
      "source": [
        "!wget -q --show-progress https://raw.githubusercontent.com/overfit-ir/persian-twitter-ner/master/twitter_data/persian-ner-twitter-data/train.txt\n",
        "!wget -q --show-progress https://raw.githubusercontent.com/overfit-ir/persian-twitter-ner/master/twitter_data/persian-ner-twitter-data/test.txt\n",
        "!wget -q --show-progress https://raw.githubusercontent.com/overfit-ir/persian-twitter-ner/master/twitter_data/persian-ner-twitter-data/dev.txt\n",
        "!mkdir data_twitter && mv train.txt data_twitter && mv test.txt data_twitter && mv dev.txt data_twitter"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train.txt           100%[===================>]   2.20M  --.-KB/s    in 0.05s   \n",
            "test.txt            100%[===================>] 108.10K  --.-KB/s    in 0.004s  \n",
            "dev.txt             100%[===================>] 160.83K  --.-KB/s    in 0.005s  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F_Bk-bpscy9l",
        "outputId": "6e93d774-9561-42ab-80bd-b8c8bd7938d2"
      },
      "source": [
        "!wget -q --show-progress https://raw.githubusercontent.com/overfit-ir/persian-twitter-ner/feature/add-multi-task-learning/ner_data/peyma/dev.txt\n",
        "!wget -q --show-progress https://raw.githubusercontent.com/overfit-ir/persian-twitter-ner/feature/add-multi-task-learning/ner_data/peyma/train.txt\n",
        "!wget -q --show-progress https://raw.githubusercontent.com/overfit-ir/persian-twitter-ner/feature/add-multi-task-learning/ner_data/peyma/test.txt\n",
        "!mkdir data_peyma && mv train.txt data_peyma && mv test.txt data_peyma && mv dev.txt data_peyma"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dev.txt             100%[===================>] 297.21K  --.-KB/s    in 0.008s  \n",
            "train.txt           100%[===================>]   2.64M  --.-KB/s    in 0.03s   \n",
            "test.txt            100%[===================>] 359.39K  --.-KB/s    in 0.007s  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w6ssZIt-8i_d"
      },
      "source": [
        "### Install Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Yo1uL4o7FCi",
        "outputId": "3fb0b347-ffd9-48dc-c04a-40d2b4dcd7c4"
      },
      "source": [
        "!pip -q install transformers==4.4.2\n",
        "!pip -q install sentencepiece\n",
        "!pip -q install seqeval\n",
        "!pip -q install conllu"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 2.0MB 19.9MB/s \n",
            "\u001b[K     |████████████████████████████████| 870kB 42.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.3MB 53.3MB/s \n",
            "\u001b[?25h  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[K     |████████████████████████████████| 1.2MB 22.5MB/s \n",
            "\u001b[K     |████████████████████████████████| 51kB 6.0MB/s \n",
            "\u001b[?25h  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tcikcJHwIMHN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "694afa3f-198c-4c6a-a753-f687f97b7136"
      },
      "source": [
        "import transformers\n",
        "transformers.__version__"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'4.4.2'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ne4kyMz8gBY"
      },
      "source": [
        "### Preprocess"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Of7QX16O82uF",
        "outputId": "71c65a88-3474-4e31-f1aa-f55ed048660b"
      },
      "source": [
        "!wget -q --show-progress \"https://raw.githubusercontent.com/stefan-it/fine-tuned-berts-seq/master/scripts/preprocess.py\""
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\rpreprocess.py         0%[                    ]       0  --.-KB/s               \rpreprocess.py       100%[===================>]     991  --.-KB/s    in 0s      \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OcqvEZ-r9frk"
      },
      "source": [
        "#### Preprocess twitter data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YWFA3eSk6vxk"
      },
      "source": [
        "!cat data_twitter/train.txt | grep -v \"^#\" | cut -f 1,2 | tr '\\t' ' ' > data_twitter/train.txt.tmp\n",
        "!cat data_twitter/test.txt | grep -v \"^#\" | cut -f 1,2 | tr '\\t' ' ' > data_twitter/test.txt.tmp\n",
        "!cat data_twitter/dev.txt | grep -v \"^#\" | cut -f 1,2 | tr '\\t' ' ' > data_twitter/dev.txt.tmp"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6KAjbvS191T5"
      },
      "source": [
        "!mkdir processed_data_twitter"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QtGsUfJA7MGm",
        "outputId": "7edbb8ff-51ef-49e5-dcd2-2165fe07cbd1"
      },
      "source": [
        "!python3 preprocess.py data_twitter/dev.txt.tmp HooshvareLab/bert-base-parsbert-uncased 256 > processed_data_twitter/dev.txt\n",
        "!python3 preprocess.py data_twitter/train.txt.tmp HooshvareLab/bert-base-parsbert-uncased 256 > processed_data_twitter/train.txt\n",
        "!python3 preprocess.py data_twitter/test.txt.tmp HooshvareLab/bert-base-parsbert-uncased 256 > processed_data_twitter/test.txt"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\rDownloading:   0% 0.00/434 [00:00<?, ?B/s]\rDownloading: 100% 434/434 [00:00<00:00, 689kB/s]\n",
            "\rDownloading:   0% 0.00/1.22M [00:00<?, ?B/s]\rDownloading: 100% 1.22M/1.22M [00:00<00:00, 34.6MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JQsAOHeZ9iVQ"
      },
      "source": [
        "#### Preprocess Peyma"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wP27X5o1Ns7b"
      },
      "source": [
        "with open('data_peyma/train.txt') as file:\n",
        "  content = ''\n",
        "  for line in file.readlines():\n",
        "    content += line.replace(' ', '\\u200c')\n",
        "with open('data_peyma/train.txt.tmp', 'w') as file:\n",
        "  file.write(content)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cXyqubCZNuG2"
      },
      "source": [
        "with open('data_peyma/test.txt') as file:\n",
        "  content = ''\n",
        "  for line in file.readlines():\n",
        "    content += line.replace(' ', '\\u200c')\n",
        "with open('data_peyma/test.txt.tmp', 'w') as file:\n",
        "  file.write(content)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wdbIA0TlNxXA"
      },
      "source": [
        "with open('data_peyma/dev.txt') as file:\n",
        "  content = ''\n",
        "  for line in file.readlines():\n",
        "    content += line.replace(' ', '\\u200c')\n",
        "with open('data_peyma/dev.txt.tmp', 'w') as file:\n",
        "  file.write(content)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FLUMBFnI9ldc"
      },
      "source": [
        "!cat data_peyma/train.txt.tmp | grep -v \"^#\" | cut -f 1,2 | tr '|' ' ' > data_peyma/train.txt.tmp2\n",
        "!cat data_peyma/test.txt.tmp | grep -v \"^#\" | cut -f 1,2 | tr '|' ' ' > data_peyma/test.txt.tmp2\n",
        "!cat data_peyma/dev.txt.tmp | grep -v \"^#\" | cut -f 1,2 | tr '|' ' ' > data_peyma/dev.txt.tmp2"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S9F3KuFR-QZJ"
      },
      "source": [
        "!mkdir processed_data_peyma"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9AynaHLb-TpN"
      },
      "source": [
        "!python3 preprocess.py data_peyma/dev.txt.tmp2 HooshvareLab/bert-base-parsbert-uncased 256 > processed_data_peyma/dev.txt\n",
        "!python3 preprocess.py data_peyma/train.txt.tmp2 HooshvareLab/bert-base-parsbert-uncased 256 > processed_data_peyma/train.txt\n",
        "!python3 preprocess.py data_peyma/test.txt.tmp2 HooshvareLab/bert-base-parsbert-uncased 256 > processed_data_peyma/test.txt"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ldFgYj3U8mA5"
      },
      "source": [
        "### Retrieve Labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iR4L971T9IVi"
      },
      "source": [
        "!cat processed_data_twitter/train.txt processed_data_twitter/test.txt processed_data_twitter/dev.txt | cut -d \" \" -f 2 | grep -v \"^$\"| sort | uniq > labels_twitter.txt"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4NqWmNT3-wLT"
      },
      "source": [
        "!cat processed_data_peyma/train.txt processed_data_peyma/test.txt processed_data_peyma/dev.txt | cut -d \" \" -f 2 | grep -v \"^$\"| sort | uniq > labels_peyma.txt"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "STAnAZxi8ri9"
      },
      "source": [
        "### Multi-task Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6s242anr9L7A",
        "outputId": "5e17e8bd-b062-4eed-8728-b1f7f1864c01"
      },
      "source": [
        "!python3 run_tf_ner.py \\\n",
        "--data_dir_twitter ./processed_data_twitter/ \\\n",
        "--data_dir_peyma ./processed_data_peyma/ \\\n",
        "--labels_twitter labels_twitter.txt \\\n",
        "--labels_peyma labels_peyma.txt \\\n",
        "--model_name_or_path HooshvareLab/bert-base-parsbert-uncased \\\n",
        "--output_dir drive/MyDrive/eval/ \\\n",
        "--max_seq_length_twitter  256 \\\n",
        "--max_seq_length_peyma  256 \\\n",
        "--per_device_train_batch_size 8 \\\n",
        "--save_steps 3000 \\\n",
        "--save_total_limit 1 \\\n",
        "--eval_steps 300 \\\n",
        "--logging_steps 300 \\\n",
        "--logging_first_step True \\\n",
        "--evaluation_strategy steps \\\n",
        "--seed 1 \\\n",
        "--num_train_epochs 5 \\\n",
        "--max_step 2700 \\\n",
        "--load_best_model_at_end \\\n",
        "--metric_for_best_model f1-score \\\n",
        "--greater_is_better yes \\\n",
        "--do_train \\\n",
        "--do_eval \\\n",
        "--do_predict"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-04-16 17:29:50.973393: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "[INFO|training_args.py:631] 2021-04-16 17:29:52,185 >> PyTorch: setting up devices\n",
            "[INFO|training_args.py:555] 2021-04-16 17:29:52,217 >> The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
            "[INFO|training_args_tf.py:192] 2021-04-16 17:29:52,223 >> Tensorflow: setting up strategy\n",
            "2021-04-16 17:29:52.229099: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
            "2021-04-16 17:29:52.229357: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
            "2021-04-16 17:29:52.229687: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-04-16 17:29:52.230301: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
            "pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5\n",
            "coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s\n",
            "2021-04-16 17:29:52.230354: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "2021-04-16 17:29:52.361120: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
            "2021-04-16 17:29:52.361212: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
            "2021-04-16 17:29:52.535390: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
            "2021-04-16 17:29:52.551445: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
            "2021-04-16 17:29:52.828731: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
            "2021-04-16 17:29:52.856164: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n",
            "2021-04-16 17:29:52.861347: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
            "2021-04-16 17:29:52.861478: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-04-16 17:29:52.862132: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-04-16 17:29:52.864894: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
            "2021-04-16 17:29:52.865742: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
            "2021-04-16 17:29:52.865854: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-04-16 17:29:52.866421: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
            "pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5\n",
            "coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s\n",
            "2021-04-16 17:29:52.866472: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "2021-04-16 17:29:52.866506: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
            "2021-04-16 17:29:52.866529: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
            "2021-04-16 17:29:52.866552: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
            "2021-04-16 17:29:52.866585: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
            "2021-04-16 17:29:52.866616: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
            "2021-04-16 17:29:52.866649: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n",
            "2021-04-16 17:29:52.866673: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
            "2021-04-16 17:29:52.866744: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-04-16 17:29:52.867322: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-04-16 17:29:52.867889: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
            "2021-04-16 17:29:52.870007: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "2021-04-16 17:29:57.246794: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2021-04-16 17:29:57.246842: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n",
            "2021-04-16 17:29:57.246857: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n",
            "2021-04-16 17:29:57.252201: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-04-16 17:29:57.252862: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-04-16 17:29:57.253441: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-04-16 17:29:57.253955: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2021-04-16 17:29:57.254012: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 13994 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
            "04/16/2021 17:29:57 - INFO - __main__ -   n_replicas: 1, distributed training: False, 16-bits training: False\n",
            "04/16/2021 17:29:57 - INFO - __main__ -   Training/evaluation parameters TFTrainingArguments(output_dir='drive/MyDrive/eval/', overwrite_output_dir=False, do_train=True, do_eval=True, do_predict=True, evaluation_strategy=<IntervalStrategy.STEPS: 'steps'>, prediction_loss_only=False, per_device_train_batch_size=8, per_device_eval_batch_size=8, per_gpu_train_batch_size=None, per_gpu_eval_batch_size=None, gradient_accumulation_steps=1, eval_accumulation_steps=None, learning_rate=5e-05, weight_decay=0.0, adam_beta1=0.9, adam_beta2=0.999, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=5.0, max_steps=2700, lr_scheduler_type=<SchedulerType.LINEAR: 'linear'>, warmup_ratio=0.0, warmup_steps=0, logging_dir='runs/Apr16_17-29-52_3cebdb915881', logging_strategy=<IntervalStrategy.STEPS: 'steps'>, logging_first_step=True, logging_steps=300, save_strategy=<IntervalStrategy.STEPS: 'steps'>, save_steps=3000, save_total_limit=1, no_cuda=False, seed=1, fp16=False, fp16_opt_level='O1', fp16_backend='auto', fp16_full_eval=False, local_rank=-1, tpu_num_cores=None, tpu_metrics_debug=False, debug=False, dataloader_drop_last=False, eval_steps=300, dataloader_num_workers=0, past_index=-1, run_name='drive/MyDrive/eval/', disable_tqdm=False, remove_unused_columns=True, label_names=None, load_best_model_at_end=True, metric_for_best_model='f1-score', greater_is_better=True, ignore_data_skip=False, sharded_ddp=[], deepspeed=None, label_smoothing_factor=0.0, adafactor=False, group_by_length=False, report_to=['tensorboard'], ddp_find_unused_parameters=None, dataloader_pin_memory=True, skip_memory_metrics=False, tpu_name=None, tpu_zone=None, gcp_project=None, poly_power=1.0, xla=False)\n",
            "[INFO|configuration_utils.py:463] 2021-04-16 17:29:57,284 >> loading configuration file https://huggingface.co/HooshvareLab/bert-base-parsbert-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/d3b7c3283a6a4ad4471f59269c9de8adadfab0b05eebf49a64e046fca56cdab2.58cfea678e7bd2c1de3bfd4a5357101526b9fbc32a994b9456047e55b0afbebe\n",
            "[INFO|configuration_utils.py:499] 2021-04-16 17:29:57,284 >> Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"B-EVE\",\n",
            "    \"1\": \"B-LOC\",\n",
            "    \"2\": \"B-NAT\",\n",
            "    \"3\": \"B-ORG\",\n",
            "    \"4\": \"B-PER\",\n",
            "    \"5\": \"B-POG\",\n",
            "    \"6\": \"I-EVE\",\n",
            "    \"7\": \"I-LOC\",\n",
            "    \"8\": \"I-NAT\",\n",
            "    \"9\": \"I-ORG\",\n",
            "    \"10\": \"I-PER\",\n",
            "    \"11\": \"I-POG\",\n",
            "    \"12\": \"O\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"B-EVE\": 0,\n",
            "    \"B-LOC\": 1,\n",
            "    \"B-NAT\": 2,\n",
            "    \"B-ORG\": 3,\n",
            "    \"B-PER\": 4,\n",
            "    \"B-POG\": 5,\n",
            "    \"I-EVE\": 6,\n",
            "    \"I-LOC\": 7,\n",
            "    \"I-NAT\": 8,\n",
            "    \"I-ORG\": 9,\n",
            "    \"I-PER\": 10,\n",
            "    \"I-POG\": 11,\n",
            "    \"O\": 12\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.4.2\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 100000\n",
            "}\n",
            "\n",
            "[INFO|configuration_utils.py:463] 2021-04-16 17:29:57,385 >> loading configuration file https://huggingface.co/HooshvareLab/bert-base-parsbert-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/d3b7c3283a6a4ad4471f59269c9de8adadfab0b05eebf49a64e046fca56cdab2.58cfea678e7bd2c1de3bfd4a5357101526b9fbc32a994b9456047e55b0afbebe\n",
            "[INFO|configuration_utils.py:499] 2021-04-16 17:29:57,386 >> Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"B_DAT\",\n",
            "    \"1\": \"B_LOC\",\n",
            "    \"2\": \"B_MON\",\n",
            "    \"3\": \"B_ORG\",\n",
            "    \"4\": \"B_PCT\",\n",
            "    \"5\": \"B_PER\",\n",
            "    \"6\": \"B_TIM\",\n",
            "    \"7\": \"I_DAT\",\n",
            "    \"8\": \"I_LOC\",\n",
            "    \"9\": \"I_MON\",\n",
            "    \"10\": \"I_ORG\",\n",
            "    \"11\": \"I_PCT\",\n",
            "    \"12\": \"I_PER\",\n",
            "    \"13\": \"I_TIM\",\n",
            "    \"14\": \"O\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"B_DAT\": 0,\n",
            "    \"B_LOC\": 1,\n",
            "    \"B_MON\": 2,\n",
            "    \"B_ORG\": 3,\n",
            "    \"B_PCT\": 4,\n",
            "    \"B_PER\": 5,\n",
            "    \"B_TIM\": 6,\n",
            "    \"I_DAT\": 7,\n",
            "    \"I_LOC\": 8,\n",
            "    \"I_MON\": 9,\n",
            "    \"I_ORG\": 10,\n",
            "    \"I_PCT\": 11,\n",
            "    \"I_PER\": 12,\n",
            "    \"I_TIM\": 13,\n",
            "    \"O\": 14\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.4.2\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 100000\n",
            "}\n",
            "\n",
            "[INFO|configuration_utils.py:463] 2021-04-16 17:29:57,403 >> loading configuration file https://huggingface.co/HooshvareLab/bert-base-parsbert-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/d3b7c3283a6a4ad4471f59269c9de8adadfab0b05eebf49a64e046fca56cdab2.58cfea678e7bd2c1de3bfd4a5357101526b9fbc32a994b9456047e55b0afbebe\n",
            "[INFO|configuration_utils.py:499] 2021-04-16 17:29:57,403 >> Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.4.2\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 100000\n",
            "}\n",
            "\n",
            "[INFO|tokenization_utils_base.py:1702] 2021-04-16 17:29:57,492 >> loading file https://huggingface.co/HooshvareLab/bert-base-parsbert-uncased/resolve/main/vocab.txt from cache at /root/.cache/huggingface/transformers/b80b05f64dc19f3c880b7074ef09108d0bc244e4b6f50d6dba094da0f1c231fd.6699f2ee4745b6531f79b9781879071b6ace2d2768df83889391421fb44d4474\n",
            "[INFO|tokenization_utils_base.py:1702] 2021-04-16 17:29:57,492 >> loading file https://huggingface.co/HooshvareLab/bert-base-parsbert-uncased/resolve/main/added_tokens.json from cache at None\n",
            "[INFO|tokenization_utils_base.py:1702] 2021-04-16 17:29:57,492 >> loading file https://huggingface.co/HooshvareLab/bert-base-parsbert-uncased/resolve/main/special_tokens_map.json from cache at None\n",
            "[INFO|tokenization_utils_base.py:1702] 2021-04-16 17:29:57,493 >> loading file https://huggingface.co/HooshvareLab/bert-base-parsbert-uncased/resolve/main/tokenizer_config.json from cache at None\n",
            "[INFO|tokenization_utils_base.py:1702] 2021-04-16 17:29:57,493 >> loading file https://huggingface.co/HooshvareLab/bert-base-parsbert-uncased/resolve/main/tokenizer.json from cache at None\n",
            "04/16/2021 17:29:57 - INFO - filelock -   Lock 140279405811920 acquired on /root/.cache/huggingface/transformers/9cdad356c7d6956a9814a7cd822941b9a7bc7f3b450273d48f5a6626d97413a4.f8b29776d705d818b1b6d82629b12d40a9867a4c1e55e043dd81c99c2e36a246.h5.lock\n",
            "[INFO|file_utils.py:1386] 2021-04-16 17:29:57,623 >> https://huggingface.co/HooshvareLab/bert-base-parsbert-uncased/resolve/main/tf_model.h5 not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmplaw_31_r\n",
            "Downloading: 100% 963M/963M [00:18<00:00, 52.6MB/s]\n",
            "[INFO|file_utils.py:1390] 2021-04-16 17:30:16,258 >> storing https://huggingface.co/HooshvareLab/bert-base-parsbert-uncased/resolve/main/tf_model.h5 in cache at /root/.cache/huggingface/transformers/9cdad356c7d6956a9814a7cd822941b9a7bc7f3b450273d48f5a6626d97413a4.f8b29776d705d818b1b6d82629b12d40a9867a4c1e55e043dd81c99c2e36a246.h5\n",
            "[INFO|file_utils.py:1393] 2021-04-16 17:30:16,258 >> creating metadata file for /root/.cache/huggingface/transformers/9cdad356c7d6956a9814a7cd822941b9a7bc7f3b450273d48f5a6626d97413a4.f8b29776d705d818b1b6d82629b12d40a9867a4c1e55e043dd81c99c2e36a246.h5\n",
            "04/16/2021 17:30:16 - INFO - filelock -   Lock 140279405811920 released on /root/.cache/huggingface/transformers/9cdad356c7d6956a9814a7cd822941b9a7bc7f3b450273d48f5a6626d97413a4.f8b29776d705d818b1b6d82629b12d40a9867a4c1e55e043dd81c99c2e36a246.h5.lock\n",
            "[INFO|modeling_tf_utils.py:1240] 2021-04-16 17:30:16,258 >> loading weights file https://huggingface.co/HooshvareLab/bert-base-parsbert-uncased/resolve/main/tf_model.h5 from cache at /root/.cache/huggingface/transformers/9cdad356c7d6956a9814a7cd822941b9a7bc7f3b450273d48f5a6626d97413a4.f8b29776d705d818b1b6d82629b12d40a9867a4c1e55e043dd81c99c2e36a246.h5\n",
            "2021-04-16 17:30:16.669304: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
            "2021-04-16 17:30:19.246416: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11\n",
            "[WARNING|modeling_tf_utils.py:1298] 2021-04-16 17:30:20,188 >> All model checkpoint layers were used when initializing TFBertForTokenClassification.\n",
            "\n",
            "[WARNING|modeling_tf_utils.py:1302] 2021-04-16 17:30:20,189 >> Some layers of TFBertForTokenClassification were not initialized from the model checkpoint at HooshvareLab/bert-base-parsbert-uncased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "[INFO|modeling_tf_utils.py:1240] 2021-04-16 17:30:20,210 >> loading weights file https://huggingface.co/HooshvareLab/bert-base-parsbert-uncased/resolve/main/tf_model.h5 from cache at /root/.cache/huggingface/transformers/9cdad356c7d6956a9814a7cd822941b9a7bc7f3b450273d48f5a6626d97413a4.f8b29776d705d818b1b6d82629b12d40a9867a4c1e55e043dd81c99c2e36a246.h5\n",
            "[WARNING|modeling_tf_utils.py:1298] 2021-04-16 17:30:21,220 >> All model checkpoint layers were used when initializing TFBertForTokenClassification.\n",
            "\n",
            "[WARNING|modeling_tf_utils.py:1302] 2021-04-16 17:30:21,220 >> Some layers of TFBertForTokenClassification were not initialized from the model checkpoint at HooshvareLab/bert-base-parsbert-uncased and are newly initialized: ['classifier']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "04/16/2021 17:30:21 - INFO - utils_ner -   Writing example 0 of 6417\n",
            "04/16/2021 17:30:21 - INFO - utils_ner -   *** Example ***\n",
            "04/16/2021 17:30:21 - INFO - utils_ner -   guid: train-1\n",
            "04/16/2021 17:30:21 - INFO - utils_ner -   tokens: [CLS] چهارمین قهرمانی فلو ##مین ##نس ##ه در برزیل [SEP]\n",
            "04/16/2021 17:30:21 - INFO - utils_ner -   input_ids: 2 6968 5179 13879 2231 8049 1177 2028 6674 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/16/2021 17:30:21 - INFO - utils_ner -   input_mask: 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/16/2021 17:30:21 - INFO - utils_ner -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/16/2021 17:30:21 - INFO - utils_ner -   label_ids: -100 12 12 3 -100 -100 -100 12 1 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
            "04/16/2021 17:30:21 - INFO - utils_ner -   *** Example ***\n",
            "04/16/2021 17:30:21 - INFO - utils_ner -   guid: train-2\n",
            "04/16/2021 17:30:21 - INFO - utils_ner -   tokens: [CLS] زندگی سلام کورا ##سا ##يو بلیز سیشل و نايورو خراسان ورزشی دو بیانضباطی و دو واکنش متفاوت از فرهاد سرخهای پایتخت در اندیشه دبل [SEP]\n",
            "04/16/2021 17:30:21 - INFO - utils_ner -   input_ids: 2 2763 3132 56694 7779 5657 43533 73166 331 51087 4985 4874 2136 34955 331 2136 4104 4215 2036 8723 52933 4840 2028 6793 53073 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/16/2021 17:30:21 - INFO - utils_ner -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/16/2021 17:30:21 - INFO - utils_ner -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/16/2021 17:30:21 - INFO - utils_ner -   label_ids: -100 12 12 12 -100 -100 12 12 12 12 3 9 12 12 12 12 12 12 12 4 3 9 12 12 12 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
            "04/16/2021 17:30:21 - INFO - utils_ner -   *** Example ***\n",
            "04/16/2021 17:30:21 - INFO - utils_ner -   guid: train-3\n",
            "04/16/2021 17:30:21 - INFO - utils_ner -   tokens: [CLS] سال [UNK] را سالی که در ان بایرن همه جامهای ممکن را برد و حالا [UNK] تکرار کسب تمامی عناوین ممکن لیگ قهرمانان بوندس لیگا جام حذفی المان سوپرکاپ اروپا ( سال [UNK] قهرمان جام باشگاههای جهان ) [SEP]\n",
            "04/16/2021 17:30:21 - INFO - utils_ner -   input_ids: 2 2101 1 2049 5622 2046 2028 2050 12028 2440 29809 3085 2049 3736 331 3826 1 5439 3161 3629 9337 3085 3820 7112 27507 25372 2533 10236 4016 43671 3509 9 2101 1 6000 2533 9489 2685 10 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/16/2021 17:30:21 - INFO - utils_ner -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/16/2021 17:30:21 - INFO - utils_ner -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/16/2021 17:30:21 - INFO - utils_ner -   label_ids: -100 12 12 12 12 12 12 12 3 12 12 12 12 12 12 12 12 12 12 12 12 12 0 6 0 6 0 6 6 0 6 12 12 12 0 6 6 6 12 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
            "04/16/2021 17:30:21 - INFO - utils_ner -   *** Example ***\n",
            "04/16/2021 17:30:21 - INFO - utils_ner -   guid: train-4\n",
            "04/16/2021 17:30:21 - INFO - utils_ner -   tokens: [CLS] اگه از هر قریه کشور یک ازمایش dna گرفته شود باز خاد دیدیم که نه پشتون پشتون است نه تاجیک تاجیک فخر قومی و ملیتی قصه کچ ##ری قروت خاد شد مط ##من استم تقریبا ده درصد حشمت غنی هم هزاره است مثل یک سومالیایی سیا پوست ده یوتیوب نشان میداد که ده درصد چین ##ایی است دراصل از خاکی ##م و در خاکی ##م [SEP]\n",
            "04/16/2021 17:30:21 - INFO - utils_ner -   input_ids: 2 12915 2036 2202 37139 2116 2076 4764 17023 2563 2268 2266 11138 10725 2046 2505 55145 55145 2045 2505 10444 10444 14935 13097 331 24339 8468 21727 2059 94422 11138 2087 2294 2316 9661 4557 2326 2361 25549 6648 2063 16365 2045 3452 2076 52621 10117 4531 2326 15916 2555 4861 2046 2326 2361 3443 2100 2045 75108 2036 12538 1155 331 2028 12538 1155 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/16/2021 17:30:21 - INFO - utils_ner -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/16/2021 17:30:21 - INFO - utils_ner -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/16/2021 17:30:21 - INFO - utils_ner -   label_ids: -100 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 2 2 12 12 2 2 12 12 12 12 12 12 -100 12 12 12 12 -100 12 12 12 12 12 12 12 12 12 12 12 2 12 12 12 3 12 12 12 12 12 12 -100 12 12 12 12 -100 12 12 12 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
            "04/16/2021 17:30:21 - INFO - utils_ner -   *** Example ***\n",
            "04/16/2021 17:30:21 - INFO - utils_ner -   guid: train-5\n",
            "04/16/2021 17:30:21 - INFO - utils_ner -   tokens: [CLS] اختلافات سپاه تهران و فرماندهی سپاه انکار ##شدنی نیست نکته این است که برای طرفین ماجرا این یک اختلاف درون خانواده انقلاب و سپاه است حالا bbc هم مرده ##خوری میکند وگرنه رسانه ملکه و سربازان فارسیزبان ##ش با جنگ و سپاه مشکل ریشهای دارند از فتحالمبین و بیتالمقدس که همه یکدست بودند [SEP]\n",
            "04/16/2021 17:30:21 - INFO - utils_ner -   input_ids: 2 7329 4008 2402 331 7032 4008 7108 15891 2380 3926 2042 2045 2046 2073 8015 5940 2042 2076 4201 4710 3045 2858 331 4008 2045 3826 14208 2063 11627 11883 2313 11874 3080 12352 331 8370 30760 1176 2037 2941 331 4008 2524 15983 2522 2036 54398 331 24449 2046 2440 19160 2820 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/16/2021 17:30:21 - INFO - utils_ner -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/16/2021 17:30:21 - INFO - utils_ner -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/16/2021 17:30:21 - INFO - utils_ner -   label_ids: -100 12 3 9 12 12 3 12 -100 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 3 12 12 3 12 12 -100 12 12 12 4 12 12 12 -100 12 12 12 3 12 12 12 12 0 12 0 12 12 12 12 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
            "04/16/2021 17:30:34 - INFO - utils_ner -   Writing example 0 of 8031\n",
            "04/16/2021 17:30:34 - INFO - utils_ner -   *** Example ***\n",
            "04/16/2021 17:30:34 - INFO - utils_ner -   guid: train-1\n",
            "04/16/2021 17:30:34 - INFO - utils_ner -   tokens: [CLS] مدیران چهارمین جشنواره فیلم و عکس فناوری و صنعتی معرفی شدند [SEP]\n",
            "04/16/2021 17:30:34 - INFO - utils_ner -   input_ids: 2 3518 6968 3617 2627 331 3679 3166 331 3762 3131 2995 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/16/2021 17:30:34 - INFO - utils_ner -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/16/2021 17:30:34 - INFO - utils_ner -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/16/2021 17:30:34 - INFO - utils_ner -   label_ids: -100 14 14 14 14 14 14 14 14 14 14 14 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
            "04/16/2021 17:30:34 - INFO - utils_ner -   *** Example ***\n",
            "04/16/2021 17:30:34 - INFO - utils_ner -   guid: train-2\n",
            "04/16/2021 17:30:34 - INFO - utils_ner -   tokens: [CLS] به گزارش خبرگزاری مهر ، سعید پورعلی معاون فرهنگی جهاد دانشگاهی کشور با تاکید بر اینکه سینما یکی از موثرترین روشهای فرهنگسازی در حوزه صنعت و تولید است ، گفت : با توجه به گستردگی روزافزون سینما و صنعت در کشور ، این دو نمیتوانند از یکدیگر کنارهگیری کنند . [SEP]\n",
            "04/16/2021 17:30:34 - INFO - utils_ner -   input_ids: 2 2031 2248 3070 2938 300 5587 27994 2693 2968 4063 6171 2116 2037 2617 2043 2265 4148 2375 2036 17441 5399 12722 2028 2743 2572 331 2278 2045 300 2117 17 2037 2426 2031 13872 13227 4148 331 2572 2028 2116 300 2042 2136 6545 2036 4468 13974 2362 15 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/16/2021 17:30:34 - INFO - utils_ner -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/16/2021 17:30:34 - INFO - utils_ner -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/16/2021 17:30:34 - INFO - utils_ner -   label_ids: -100 14 14 3 10 14 5 12 14 14 3 10 10 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
            "04/16/2021 17:30:34 - INFO - utils_ner -   *** Example ***\n",
            "04/16/2021 17:30:34 - INFO - utils_ner -   guid: train-3\n",
            "04/16/2021 17:30:34 - INFO - utils_ner -   tokens: [CLS] چهبسا امروز در کشورهای پیشرفته ، جایگاه فرهنگ به عنوان یکی از محورهای صنعت و اقتصاد جای خود را باز کرده است . [SEP]\n",
            "04/16/2021 17:30:34 - INFO - utils_ner -   input_ids: 2 36729 2539 2028 2835 6177 300 3933 3251 2031 2339 2375 2036 7094 2572 331 2529 2585 2081 2049 2266 2224 2045 15 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/16/2021 17:30:34 - INFO - utils_ner -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/16/2021 17:30:34 - INFO - utils_ner -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/16/2021 17:30:34 - INFO - utils_ner -   label_ids: -100 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
            "04/16/2021 17:30:34 - INFO - utils_ner -   *** Example ***\n",
            "04/16/2021 17:30:34 - INFO - utils_ner -   guid: train-4\n",
            "04/16/2021 17:30:34 - INFO - utils_ner -   tokens: [CLS] وی ادامه داد : متاسفانه با توجه به ساختار دولتی فرهنگ و هنر در کشور ما ، اینگونه پذیرفته شده که فرهنگ مقولهای هزینهبر است که منابع درامدی نامشخصی دارد . [SEP]\n",
            "04/16/2021 17:30:34 - INFO - utils_ner -   input_ids: 2 2155 2384 2197 17 3817 2037 2426 2031 4906 3324 3251 331 3309 2028 2116 2179 300 5135 6533 2110 2046 3251 26245 30249 2045 2046 2973 8783 41937 2192 15 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/16/2021 17:30:34 - INFO - utils_ner -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/16/2021 17:30:34 - INFO - utils_ner -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/16/2021 17:30:34 - INFO - utils_ner -   label_ids: -100 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
            "04/16/2021 17:30:34 - INFO - utils_ner -   *** Example ***\n",
            "04/16/2021 17:30:34 - INFO - utils_ner -   guid: train-5\n",
            "04/16/2021 17:30:34 - INFO - utils_ner -   tokens: [CLS] به نظر میرسد که همگامی فرهنگ و اقتصاد و صنعت بتواند علاوه بر تاثیرات شگرف ##ت بر حوزه اقتصاد و صنعت ، فرهنگ را نیز به سمت اصلاح ساختارهای هزینهکرد سوق دهد . [SEP]\n",
            "04/16/2021 17:30:34 - INFO - utils_ner -   input_ids: 2 2031 2363 3179 2046 37300 3251 331 2529 331 2572 4560 3377 2043 8358 25351 1174 2043 2743 2529 331 2572 300 3251 2049 2174 2031 3282 2942 12296 27032 9752 3127 15 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/16/2021 17:30:34 - INFO - utils_ner -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/16/2021 17:30:34 - INFO - utils_ner -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/16/2021 17:30:34 - INFO - utils_ner -   label_ids: -100 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 -100 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
            "04/16/2021 17:30:49 - INFO - utils_ner -   Writing example 0 of 446\n",
            "04/16/2021 17:30:49 - INFO - utils_ner -   *** Example ***\n",
            "04/16/2021 17:30:49 - INFO - utils_ner -   guid: dev-1\n",
            "04/16/2021 17:30:49 - INFO - utils_ner -   tokens: [CLS] باید از امید اروپاییها برید مخصوصا ایرانیانی که در پارلمانها هستند و طوری وانمود میکنند که رژیم ایران یک رژیم عادی ولی سختگیر است [SEP]\n",
            "04/16/2021 17:30:49 - INFO - utils_ner -   input_ids: 2 2212 2036 2878 13864 22242 8779 33874 2046 2028 66309 2373 331 4624 19439 2484 2046 3958 2119 2076 3958 5168 2752 24199 2045 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/16/2021 17:30:49 - INFO - utils_ner -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/16/2021 17:30:49 - INFO - utils_ner -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/16/2021 17:30:49 - INFO - utils_ner -   label_ids: -100 12 12 12 12 12 12 2 12 12 12 12 12 12 12 12 12 12 1 12 12 12 12 12 12 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
            "04/16/2021 17:30:49 - INFO - utils_ner -   *** Example ***\n",
            "04/16/2021 17:30:49 - INFO - utils_ner -   guid: dev-2\n",
            "04/16/2021 17:30:49 - INFO - utils_ner -   tokens: [CLS] پیدیاف اقتصاد سیاسی نیکی ##تین پیدا میشه سینا [SEP]\n",
            "04/16/2021 17:30:49 - INFO - utils_ner -   input_ids: 2 64971 2529 2809 12466 9847 2880 11290 8588 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/16/2021 17:30:49 - INFO - utils_ner -   input_mask: 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/16/2021 17:30:49 - INFO - utils_ner -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/16/2021 17:30:49 - INFO - utils_ner -   label_ids: -100 12 12 12 12 -100 12 12 4 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
            "04/16/2021 17:30:49 - INFO - utils_ner -   *** Example ***\n",
            "04/16/2021 17:30:49 - INFO - utils_ner -   guid: dev-3\n",
            "04/16/2021 17:30:49 - INFO - utils_ner -   tokens: [CLS] ذهنم به گوشههای دورتر ان بران ##م از همان کورس ( حالا به نام کاج ) اکنون یک دختر اول نمره عمومی کانک ##ور شده است یاد ان روز شوم و شام غربت در خاطرم زنده شد شمسی ##ه نشان داد که خم میشویم اما نمیش ##کنیم [UNK] [SEP]\n",
            "04/16/2021 17:30:49 - INFO - utils_ner -   input_ids: 2 18251 2031 28171 17432 2050 14648 1155 2036 2745 20921 9 3826 2031 2410 22605 10 3113 2076 4589 2389 8558 2899 21347 2034 2110 2045 2786 2050 2182 7834 331 7428 23200 2028 27099 4797 2087 11364 1177 2555 2197 2046 8097 7333 2195 7708 19493 1 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/16/2021 17:30:49 - INFO - utils_ner -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/16/2021 17:30:49 - INFO - utils_ner -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/16/2021 17:30:49 - INFO - utils_ner -   label_ids: -100 12 12 12 12 12 12 -100 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 -100 12 12 12 12 12 12 12 12 12 12 12 12 12 4 -100 12 12 12 12 12 12 12 -100 12 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
            "04/16/2021 17:30:49 - INFO - utils_ner -   *** Example ***\n",
            "04/16/2021 17:30:49 - INFO - utils_ner -   guid: dev-4\n",
            "04/16/2021 17:30:49 - INFO - utils_ner -   tokens: [CLS] بیمه بیکاری حقی ##ه ##که بهتر از من میدونین هر هفته از پیرو ##ل کسر میشه و هیچ سنخیتی با ولف ##ر که کمک هزینه مستمندان هستش نداره ولی در کل موافقم وقتی میتونی کار کنی و مالیات بدی بهتره از این کمک هزینهها دور باشی [SEP]\n",
            "04/16/2021 17:30:49 - INFO - utils_ner -   input_ids: 2 2785 5231 15516 1177 2133 3446 2036 2078 87587 2202 2759 2036 11048 1173 8662 11290 331 2608 35821 2037 23921 1156 2046 2817 3145 38238 31540 18803 2752 2028 2381 27082 3043 36803 2109 8374 331 4325 6339 30664 2036 2042 2817 7748 2394 12537 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/16/2021 17:30:49 - INFO - utils_ner -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/16/2021 17:30:49 - INFO - utils_ner -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/16/2021 17:30:49 - INFO - utils_ner -   label_ids: -100 12 12 12 -100 -100 12 12 12 12 12 12 12 12 -100 12 12 12 12 12 12 12 -100 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
            "04/16/2021 17:30:49 - INFO - utils_ner -   *** Example ***\n",
            "04/16/2021 17:30:49 - INFO - utils_ner -   guid: dev-5\n",
            "04/16/2021 17:30:49 - INFO - utils_ner -   tokens: [CLS] ششم [UNK] ) در کوچههای سرش ##ور ول میگشتم که صدای روضهای حزن ##انگیز را شنیدم دل به دریا زدم و وارد گودی کرونا شدم به عمرم ندیده بودم که کسی چنین سوزی را برای زندگی سر داده باشد نه در سوفو ##کل نه در شکسپیر و نه در گوته [SEP]\n",
            "04/16/2021 17:30:49 - INFO - utils_ner -   input_ids: 2 4969 1 10 2028 20948 10969 2034 3891 46367 2046 4873 84885 35855 11297 2049 13999 2420 2031 2628 12411 331 2480 35190 28114 5564 2031 27042 12367 4703 2046 3256 2978 8544 2049 2073 2763 2140 2488 2302 2505 2028 97609 2262 2505 2028 27500 331 2505 2028 42754 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/16/2021 17:30:49 - INFO - utils_ner -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/16/2021 17:30:49 - INFO - utils_ner -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/16/2021 17:30:49 - INFO - utils_ner -   label_ids: -100 12 12 12 12 12 12 -100 12 12 12 12 12 12 -100 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 4 -100 12 12 4 12 12 12 4 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
            "04/16/2021 17:30:50 - INFO - utils_ner -   Writing example 0 of 925\n",
            "04/16/2021 17:30:50 - INFO - utils_ner -   *** Example ***\n",
            "04/16/2021 17:30:50 - INFO - utils_ner -   guid: dev-1\n",
            "04/16/2021 17:30:50 - INFO - utils_ner -   tokens: [CLS] کرج دومین شهر الوده کشور [SEP]\n",
            "04/16/2021 17:30:50 - INFO - utils_ner -   input_ids: 2 6759 4554 2317 7154 2116 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/16/2021 17:30:50 - INFO - utils_ner -   input_mask: 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/16/2021 17:30:50 - INFO - utils_ner -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/16/2021 17:30:50 - INFO - utils_ner -   label_ids: -100 1 14 14 14 14 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
            "04/16/2021 17:30:50 - INFO - utils_ner -   *** Example ***\n",
            "04/16/2021 17:30:50 - INFO - utils_ner -   guid: dev-2\n",
            "04/16/2021 17:30:50 - INFO - utils_ner -   tokens: [CLS] مدیرکل محیط زیست استان البرز با بیان اینکه با بیان اینکه موضوع شیرابه ##های زبالههای انتقال یافته در منطقه حلقه دره خطری برای این استان است ، گفت : در این مورد گزارشاتی تقدیم مدیران استان شده است . [SEP]\n",
            "04/16/2021 17:30:50 - INFO - utils_ner -   input_ids: 2 4924 3221 3868 2503 6627 2037 2500 2265 2037 2500 2265 2534 44349 2039 18802 3485 3339 2028 2692 7591 10386 12137 2073 2042 2503 2045 300 2117 17 2028 2042 2334 26324 7613 3518 2503 2110 2045 15 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/16/2021 17:30:50 - INFO - utils_ner -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/16/2021 17:30:50 - INFO - utils_ner -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/16/2021 17:30:50 - INFO - utils_ner -   label_ids: -100 14 3 10 10 10 14 14 14 14 14 14 14 14 -100 14 14 14 14 1 8 8 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 14 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
            "04/16/2021 17:30:50 - INFO - utils_ner -   *** Example ***\n",
            "04/16/2021 17:30:50 - INFO - utils_ner -   guid: dev-3\n",
            "04/16/2021 17:30:50 - INFO - utils_ner -   tokens: [CLS] به گزارش خبرگزاری تسنیم از کرج ، حسین محمدی در نشست خبری مشترک با معاون خدمات شهری شهرداری کرج که با حضور مدیرعامل سازمانهای پسماند ، پارکها و فضای سبز و نماینده منابع طبیعی در سالن کنفرانس شهرداری کرج برگزار شد ، اظهار داشت : [UNK] درصد جمعیت استان البرز در کلانشهر کرج زندگی میکنند . [SEP]\n",
            "04/16/2021 17:30:50 - INFO - utils_ner -   input_ids: 2 2031 2248 3070 5497 2036 6759 300 3833 6470 2028 3189 2814 3073 2037 2693 2887 3046 3696 6759 2046 2037 2492 3420 5734 13438 300 19253 331 3122 4860 331 3408 2973 3673 2028 5553 5804 3696 6759 2877 2087 300 2594 2158 17 1 2361 3405 2503 6627 2028 8913 6759 2763 2484 15 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/16/2021 17:30:50 - INFO - utils_ner -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/16/2021 17:30:50 - INFO - utils_ner -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/16/2021 17:30:50 - INFO - utils_ner -   label_ids: -100 14 14 3 10 14 1 14 5 12 14 14 14 14 14 14 14 14 3 10 14 14 14 14 3 10 10 10 10 10 10 14 14 3 10 14 1 8 8 8 14 14 14 14 14 14 4 11 14 1 8 14 14 1 14 14 14 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
            "04/16/2021 17:30:50 - INFO - utils_ner -   *** Example ***\n",
            "04/16/2021 17:30:50 - INFO - utils_ner -   guid: dev-4\n",
            "04/16/2021 17:30:50 - INFO - utils_ner -   tokens: [CLS] وی افزود : با همکاریهای مشترک بین ادارهکل محیط زیست و شهرداری کرج برنامههای مشترکی برای حفاظت از محیطزیست در شهر کرج در دستور کار قرار گرفته که این اقدامات اثار مثبتی داشته است . [SEP]\n",
            "04/16/2021 17:30:50 - INFO - utils_ner -   input_ids: 2 2155 2441 17 2037 5664 3073 2267 20550 3221 3868 331 3696 6759 3460 10695 2073 5120 2036 10870 2028 2317 6759 2028 3239 2109 2232 2563 2046 2042 3429 3780 7619 2398 2045 15 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/16/2021 17:30:50 - INFO - utils_ner -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/16/2021 17:30:50 - INFO - utils_ner -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/16/2021 17:30:50 - INFO - utils_ner -   label_ids: -100 14 14 14 14 14 14 14 3 10 10 14 3 10 14 14 14 14 14 14 14 1 8 14 14 14 14 14 14 14 14 14 14 14 14 14 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
            "04/16/2021 17:30:50 - INFO - utils_ner -   *** Example ***\n",
            "04/16/2021 17:30:50 - INFO - utils_ner -   guid: dev-5\n",
            "04/16/2021 17:30:50 - INFO - utils_ner -   tokens: [CLS] مدیرکل محیط زیست البرز با بیان اینکه کلانشهر کرج با چالش الودگیهای محیطزیستی درگیر است ، بیان کرد : کرج دومین شهر الوده کشور بعد از تهران است و از رشد بسیار بالایی در تراکم جمعیت و صنعت برخوردار است . [SEP]\n",
            "04/16/2021 17:30:50 - INFO - utils_ner -   input_ids: 2 4924 3221 3868 6627 2037 2500 2265 8913 6759 2037 5355 17067 33003 5616 2045 300 2500 2068 17 6759 4554 2317 7154 2116 2514 2036 2402 2045 331 2036 2664 2600 5175 2028 10753 3405 331 2572 4028 2045 15 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/16/2021 17:30:50 - INFO - utils_ner -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/16/2021 17:30:50 - INFO - utils_ner -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/16/2021 17:30:50 - INFO - utils_ner -   label_ids: -100 14 3 10 10 14 14 14 14 1 14 14 14 14 14 14 14 14 14 14 1 14 14 14 14 14 14 1 14 14 14 14 14 14 14 14 14 14 14 14 14 14 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
            "[INFO|trainer_tf.py:117] 2021-04-16 17:30:51,869 >> You are instantiating a Trainer but W&B is not installed. To use wandb logging, run `pip install wandb; wandb login` see https://docs.wandb.com/huggingface.\n",
            "[INFO|trainer_tf.py:125] 2021-04-16 17:30:51,869 >> To use comet_ml logging, run `pip/conda install comet_ml` see https://www.comet.ml/docs/python-sdk/huggingface/\n",
            "2021-04-16 17:30:51.904730: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:454] The `assert_cardinality` transformation is currently not handled by the auto-shard rewrite and will be removed.\n",
            "2021-04-16 17:30:51.904796: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:454] The `assert_cardinality` transformation is currently not handled by the auto-shard rewrite and will be removed.\n",
            "2021-04-16 17:30:51.905372: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:656] In AUTO-mode, and switching to DATA-based sharding, instead of FILE-based sharding as we cannot find appropriate reader dataset op(s) to shard. Error: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_2\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"TensorDataset/_1\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_flat_map_fn_8695\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT32\n",
            "      type: DT_INT32\n",
            "      type: DT_INT32\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n",
            "2021-04-16 17:30:51.974577: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:454] The `assert_cardinality` transformation is currently not handled by the auto-shard rewrite and will be removed.\n",
            "2021-04-16 17:30:51.974626: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:454] The `assert_cardinality` transformation is currently not handled by the auto-shard rewrite and will be removed.\n",
            "2021-04-16 17:30:51.974736: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:656] In AUTO-mode, and switching to DATA-based sharding, instead of FILE-based sharding as we cannot find appropriate reader dataset op(s) to shard. Error: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_2\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"TensorDataset/_1\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_flat_map_fn_8724\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT32\n",
            "      type: DT_INT32\n",
            "      type: DT_INT32\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n",
            "[INFO|trainer_tf.py:528] 2021-04-16 17:30:51,979 >> ***** Running training *****\n",
            "[INFO|trainer_tf.py:529] 2021-04-16 17:30:51,980 >>   Num examples = 14448\n",
            "[INFO|trainer_tf.py:531] 2021-04-16 17:30:51,980 >>   Num Epochs = 2\n",
            "[INFO|trainer_tf.py:532] 2021-04-16 17:30:51,980 >>   Instantaneous batch size per device = 8\n",
            "[INFO|trainer_tf.py:534] 2021-04-16 17:30:51,980 >>   Total train batch size (w. parallel, distributed & accumulation) = 8\n",
            "[INFO|trainer_tf.py:536] 2021-04-16 17:30:51,980 >>   Gradient Accumulation steps = 1\n",
            "[INFO|trainer_tf.py:537] 2021-04-16 17:30:51,980 >>   Steps per epoch = 1806\n",
            "[INFO|trainer_tf.py:538] 2021-04-16 17:30:51,980 >>   Total optimization steps = 2700\n",
            "2021-04-16 17:30:52.023552: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
            "2021-04-16 17:30:52.025489: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2199995000 Hz\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "04/16/2021 17:30:56 - WARNING - tensorflow -   The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "04/16/2021 17:30:57 - WARNING - tensorflow -   The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py:390: UserWarning: Using `-1` to mask the loss for the token is deprecated. Please use `-100` instead.\n",
            "  return py_builtins.overload_of(f)(*args)\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "04/16/2021 17:31:02 - WARNING - tensorflow -   The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "04/16/2021 17:31:02 - WARNING - tensorflow -   The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "[INFO|trainer_tf.py:404] 2021-04-16 17:31:09,239 >> {'loss': 2.8572686, 'learning_rate': 4.9981478e-05, 'epoch': 0.0005537098560354374, 'step': 1}\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "04/16/2021 17:31:13 - WARNING - tensorflow -   The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "04/16/2021 17:31:13 - WARNING - tensorflow -   The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "2021-04-16 17:33:29.104470: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:454] The `assert_cardinality` transformation is currently not handled by the auto-shard rewrite and will be removed.\n",
            "2021-04-16 17:33:29.104679: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:656] In AUTO-mode, and switching to DATA-based sharding, instead of FILE-based sharding as we cannot find appropriate reader dataset op(s) to shard. Error: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_2\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"TensorDataset/_1\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_flat_map_fn_8753\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT32\n",
            "      type: DT_INT32\n",
            "      type: DT_INT32\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n",
            "04/16/2021 17:33:29 - INFO - utils_ner -   ***** Running Evaluation *****\n",
            "04/16/2021 17:33:29 - INFO - utils_ner -     Num examples in dataset = 446\n",
            "04/16/2021 17:33:29 - INFO - utils_ner -     Num examples in used in evaluation = 448\n",
            "04/16/2021 17:33:29 - INFO - utils_ner -     Batch size = 8\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "04/16/2021 17:33:29 - WARNING - tensorflow -   The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "04/16/2021 17:33:29 - WARNING - tensorflow -   The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "[INFO|trainer_tf.py:404] 2021-04-16 17:33:39,074 >> {'eval_loss': 0.12095741714750018, 'eval_precision': 0.7209302325581395, 'eval_recall': 0.7598039215686274, 'eval_f1': 0.7398568019093078, 'epoch': 0.16611295681063123, 'step': 300}\n",
            "[INFO|trainer_tf.py:404] 2021-04-16 17:33:39,077 >> {'loss': 0.28578287, 'learning_rate': 4.4444445e-05, 'epoch': 0.16611295681063123, 'step': 300}\n",
            "2021-04-16 17:35:56.534524: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:454] The `assert_cardinality` transformation is currently not handled by the auto-shard rewrite and will be removed.\n",
            "2021-04-16 17:35:56.534721: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:656] In AUTO-mode, and switching to DATA-based sharding, instead of FILE-based sharding as we cannot find appropriate reader dataset op(s) to shard. Error: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_2\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"TensorDataset/_1\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_flat_map_fn_8753\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT32\n",
            "      type: DT_INT32\n",
            "      type: DT_INT32\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n",
            "04/16/2021 17:35:56 - INFO - utils_ner -   ***** Running Evaluation *****\n",
            "04/16/2021 17:35:56 - INFO - utils_ner -     Num examples in dataset = 446\n",
            "04/16/2021 17:35:56 - INFO - utils_ner -     Num examples in used in evaluation = 448\n",
            "04/16/2021 17:35:56 - INFO - utils_ner -     Batch size = 8\n",
            "[INFO|trainer_tf.py:404] 2021-04-16 17:36:04,905 >> {'eval_loss': 0.12457921675273351, 'eval_precision': 0.7086546700942588, 'eval_recall': 0.8107843137254902, 'eval_f1': 0.7562871513488798, 'epoch': 0.33222591362126247, 'step': 600}\n",
            "[INFO|trainer_tf.py:404] 2021-04-16 17:36:04,908 >> {'loss': 0.19716775, 'learning_rate': 3.8888888e-05, 'epoch': 0.33222591362126247, 'step': 600}\n",
            "2021-04-16 17:38:22.429468: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:454] The `assert_cardinality` transformation is currently not handled by the auto-shard rewrite and will be removed.\n",
            "2021-04-16 17:38:22.429687: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:656] In AUTO-mode, and switching to DATA-based sharding, instead of FILE-based sharding as we cannot find appropriate reader dataset op(s) to shard. Error: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_2\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"TensorDataset/_1\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_flat_map_fn_8753\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT32\n",
            "      type: DT_INT32\n",
            "      type: DT_INT32\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n",
            "04/16/2021 17:38:22 - INFO - utils_ner -   ***** Running Evaluation *****\n",
            "04/16/2021 17:38:22 - INFO - utils_ner -     Num examples in dataset = 446\n",
            "04/16/2021 17:38:22 - INFO - utils_ner -     Num examples in used in evaluation = 448\n",
            "04/16/2021 17:38:22 - INFO - utils_ner -     Batch size = 8\n",
            "[INFO|trainer_tf.py:404] 2021-04-16 17:38:30,807 >> {'eval_loss': 0.10742878062384469, 'eval_precision': 0.7570518653321201, 'eval_recall': 0.8156862745098039, 'eval_f1': 0.7852760736196319, 'epoch': 0.4983388704318937, 'step': 900}\n",
            "[INFO|trainer_tf.py:404] 2021-04-16 17:38:30,810 >> {'loss': 0.16207777, 'learning_rate': 3.333333e-05, 'epoch': 0.4983388704318937, 'step': 900}\n",
            "2021-04-16 17:40:48.223163: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:454] The `assert_cardinality` transformation is currently not handled by the auto-shard rewrite and will be removed.\n",
            "2021-04-16 17:40:48.223339: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:656] In AUTO-mode, and switching to DATA-based sharding, instead of FILE-based sharding as we cannot find appropriate reader dataset op(s) to shard. Error: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_2\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"TensorDataset/_1\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_flat_map_fn_8753\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT32\n",
            "      type: DT_INT32\n",
            "      type: DT_INT32\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n",
            "04/16/2021 17:40:48 - INFO - utils_ner -   ***** Running Evaluation *****\n",
            "04/16/2021 17:40:48 - INFO - utils_ner -     Num examples in dataset = 446\n",
            "04/16/2021 17:40:48 - INFO - utils_ner -     Num examples in used in evaluation = 448\n",
            "04/16/2021 17:40:48 - INFO - utils_ner -     Batch size = 8\n",
            "[INFO|trainer_tf.py:404] 2021-04-16 17:40:56,624 >> {'eval_loss': 0.09405018602098737, 'eval_precision': 0.7927308447937131, 'eval_recall': 0.7911764705882353, 'eval_f1': 0.7919528949950931, 'epoch': 0.6644518272425249, 'step': 1200}\n",
            "[INFO|trainer_tf.py:404] 2021-04-16 17:40:56,627 >> {'loss': 0.1406851, 'learning_rate': 2.7777778e-05, 'epoch': 0.6644518272425249, 'step': 1200}\n",
            "2021-04-16 17:43:14.086127: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:454] The `assert_cardinality` transformation is currently not handled by the auto-shard rewrite and will be removed.\n",
            "2021-04-16 17:43:14.086331: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:656] In AUTO-mode, and switching to DATA-based sharding, instead of FILE-based sharding as we cannot find appropriate reader dataset op(s) to shard. Error: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_2\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"TensorDataset/_1\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_flat_map_fn_8753\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT32\n",
            "      type: DT_INT32\n",
            "      type: DT_INT32\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n",
            "04/16/2021 17:43:14 - INFO - utils_ner -   ***** Running Evaluation *****\n",
            "04/16/2021 17:43:14 - INFO - utils_ner -     Num examples in dataset = 446\n",
            "04/16/2021 17:43:14 - INFO - utils_ner -     Num examples in used in evaluation = 448\n",
            "04/16/2021 17:43:14 - INFO - utils_ner -     Batch size = 8\n",
            "[INFO|trainer_tf.py:404] 2021-04-16 17:43:22,437 >> {'eval_loss': 0.08729558331625802, 'eval_precision': 0.7960526315789473, 'eval_recall': 0.8303921568627451, 'eval_f1': 0.8128598848368522, 'epoch': 0.8305647840531561, 'step': 1500}\n",
            "[INFO|trainer_tf.py:404] 2021-04-16 17:43:22,440 >> {'loss': 0.12649459, 'learning_rate': 2.2222222e-05, 'epoch': 0.8305647840531561, 'step': 1500}\n",
            "2021-04-16 17:45:39.952486: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:454] The `assert_cardinality` transformation is currently not handled by the auto-shard rewrite and will be removed.\n",
            "2021-04-16 17:45:39.952683: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:656] In AUTO-mode, and switching to DATA-based sharding, instead of FILE-based sharding as we cannot find appropriate reader dataset op(s) to shard. Error: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_2\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"TensorDataset/_1\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_flat_map_fn_8753\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT32\n",
            "      type: DT_INT32\n",
            "      type: DT_INT32\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n",
            "04/16/2021 17:45:39 - INFO - utils_ner -   ***** Running Evaluation *****\n",
            "04/16/2021 17:45:39 - INFO - utils_ner -     Num examples in dataset = 446\n",
            "04/16/2021 17:45:39 - INFO - utils_ner -     Num examples in used in evaluation = 448\n",
            "04/16/2021 17:45:39 - INFO - utils_ner -     Batch size = 8\n",
            "[INFO|trainer_tf.py:404] 2021-04-16 17:45:48,409 >> {'eval_loss': 0.08905782869883946, 'eval_precision': 0.7933579335793358, 'eval_recall': 0.8431372549019608, 'eval_f1': 0.817490494296578, 'epoch': 0.9966777408637874, 'step': 1800}\n",
            "[INFO|trainer_tf.py:404] 2021-04-16 17:45:48,412 >> {'loss': 0.115478024, 'learning_rate': 1.6666665e-05, 'epoch': 0.9966777408637874, 'step': 1800}\n",
            "2021-04-16 17:48:09.627852: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:454] The `assert_cardinality` transformation is currently not handled by the auto-shard rewrite and will be removed.\n",
            "2021-04-16 17:48:09.628032: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:656] In AUTO-mode, and switching to DATA-based sharding, instead of FILE-based sharding as we cannot find appropriate reader dataset op(s) to shard. Error: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_2\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"TensorDataset/_1\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_flat_map_fn_8753\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT32\n",
            "      type: DT_INT32\n",
            "      type: DT_INT32\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n",
            "04/16/2021 17:48:09 - INFO - utils_ner -   ***** Running Evaluation *****\n",
            "04/16/2021 17:48:09 - INFO - utils_ner -     Num examples in dataset = 446\n",
            "04/16/2021 17:48:09 - INFO - utils_ner -     Num examples in used in evaluation = 448\n",
            "04/16/2021 17:48:09 - INFO - utils_ner -     Batch size = 8\n",
            "[INFO|trainer_tf.py:404] 2021-04-16 17:48:18,058 >> {'eval_loss': 0.09285081284386772, 'eval_precision': 0.7776785714285714, 'eval_recall': 0.8539215686274509, 'eval_f1': 0.8140186915887849, 'epoch': 1.1627906976744187, 'step': 2100}\n",
            "[INFO|trainer_tf.py:404] 2021-04-16 17:48:18,062 >> {'loss': 0.04640996, 'learning_rate': 1.1111111e-05, 'epoch': 1.1627906976744187, 'step': 2100}\n",
            "2021-04-16 17:50:35.451769: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:454] The `assert_cardinality` transformation is currently not handled by the auto-shard rewrite and will be removed.\n",
            "2021-04-16 17:50:35.451952: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:656] In AUTO-mode, and switching to DATA-based sharding, instead of FILE-based sharding as we cannot find appropriate reader dataset op(s) to shard. Error: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_2\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"TensorDataset/_1\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_flat_map_fn_8753\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT32\n",
            "      type: DT_INT32\n",
            "      type: DT_INT32\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n",
            "04/16/2021 17:50:35 - INFO - utils_ner -   ***** Running Evaluation *****\n",
            "04/16/2021 17:50:35 - INFO - utils_ner -     Num examples in dataset = 446\n",
            "04/16/2021 17:50:35 - INFO - utils_ner -     Num examples in used in evaluation = 448\n",
            "04/16/2021 17:50:35 - INFO - utils_ner -     Batch size = 8\n",
            "[INFO|trainer_tf.py:404] 2021-04-16 17:50:43,785 >> {'eval_loss': 0.08843694414411273, 'eval_precision': 0.8077651515151515, 'eval_recall': 0.8362745098039216, 'eval_f1': 0.8217726396917148, 'epoch': 1.3289036544850499, 'step': 2400}\n",
            "[INFO|trainer_tf.py:404] 2021-04-16 17:50:43,788 >> {'loss': 0.042888816, 'learning_rate': 5.5555556e-06, 'epoch': 1.3289036544850499, 'step': 2400}\n",
            "2021-04-16 17:53:01.256092: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:454] The `assert_cardinality` transformation is currently not handled by the auto-shard rewrite and will be removed.\n",
            "2021-04-16 17:53:01.256304: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:656] In AUTO-mode, and switching to DATA-based sharding, instead of FILE-based sharding as we cannot find appropriate reader dataset op(s) to shard. Error: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_2\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"TensorDataset/_1\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_flat_map_fn_8753\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT32\n",
            "      type: DT_INT32\n",
            "      type: DT_INT32\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n",
            "04/16/2021 17:53:01 - INFO - utils_ner -   ***** Running Evaluation *****\n",
            "04/16/2021 17:53:01 - INFO - utils_ner -     Num examples in dataset = 446\n",
            "04/16/2021 17:53:01 - INFO - utils_ner -     Num examples in used in evaluation = 448\n",
            "04/16/2021 17:53:01 - INFO - utils_ner -     Batch size = 8\n",
            "[INFO|trainer_tf.py:404] 2021-04-16 17:53:09,709 >> {'eval_loss': 0.08865208285195487, 'eval_precision': 0.8048552754435108, 'eval_recall': 0.8450980392156863, 'eval_f1': 0.8244858919177427, 'epoch': 1.495016611295681, 'step': 2700}\n",
            "[INFO|trainer_tf.py:404] 2021-04-16 17:53:09,712 >> {'loss': 0.03963131, 'learning_rate': 0.0, 'epoch': 1.495016611295681, 'step': 2700}\n",
            "[INFO|trainer_tf.py:610] 2021-04-16 17:53:09,760 >> Training took: 0:22:17.775809\n",
            "[INFO|trainer_tf.py:785] 2021-04-16 17:53:09,760 >> Saving model in drive/MyDrive/eval/\n",
            "[INFO|configuration_utils.py:314] 2021-04-16 17:53:09,767 >> Configuration saved in drive/MyDrive/eval/config.json\n",
            "[INFO|modeling_tf_utils.py:1045] 2021-04-16 17:53:30,494 >> Model weights saved in drive/MyDrive/eval/tf_model.h5\n",
            "[INFO|tokenization_utils_base.py:1896] 2021-04-16 17:53:30,499 >> tokenizer config file saved in drive/MyDrive/eval/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:1902] 2021-04-16 17:53:30,502 >> Special tokens file saved in drive/MyDrive/eval/special_tokens_map.json\n",
            "04/16/2021 17:53:30 - INFO - __main__ -   *** Evaluate ***\n",
            "2021-04-16 17:53:30.590675: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:454] The `assert_cardinality` transformation is currently not handled by the auto-shard rewrite and will be removed.\n",
            "2021-04-16 17:53:30.590841: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:656] In AUTO-mode, and switching to DATA-based sharding, instead of FILE-based sharding as we cannot find appropriate reader dataset op(s) to shard. Error: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_2\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"TensorDataset/_1\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_flat_map_fn_8753\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT32\n",
            "      type: DT_INT32\n",
            "      type: DT_INT32\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n",
            "04/16/2021 17:53:30 - INFO - utils_ner -   ***** Running Evaluation *****\n",
            "04/16/2021 17:53:30 - INFO - utils_ner -     Num examples in dataset = 446\n",
            "04/16/2021 17:53:30 - INFO - utils_ner -     Num examples in used in evaluation = 448\n",
            "04/16/2021 17:53:30 - INFO - utils_ner -     Batch size = 8\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "04/16/2021 17:53:30 - WARNING - tensorflow -   The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "04/16/2021 17:53:30 - WARNING - tensorflow -   The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "[INFO|trainer_tf.py:404] 2021-04-16 17:53:40,529 >> {'eval_loss': 0.08865208285195487, 'eval_precision': 0.8048552754435108, 'eval_recall': 0.8450980392156863, 'eval_f1': 0.8244858919177427, 'epoch': 1.495016611295681, 'step': 2700}\n",
            "04/16/2021 17:53:40 - INFO - __main__ -   ***** Eval results *****\n",
            "04/16/2021 17:53:40 - INFO - __main__ -     eval_loss = 0.08865208285195487\n",
            "04/16/2021 17:53:40 - INFO - __main__ -     eval_precision = 0.8048552754435108\n",
            "04/16/2021 17:53:40 - INFO - __main__ -     eval_recall = 0.8450980392156863\n",
            "04/16/2021 17:53:40 - INFO - __main__ -     eval_f1 = 0.8244858919177427\n",
            "04/16/2021 17:53:40 - INFO - utils_ner -   Writing example 0 of 303\n",
            "04/16/2021 17:53:40 - INFO - utils_ner -   *** Example ***\n",
            "04/16/2021 17:53:40 - INFO - utils_ner -   guid: test-1\n",
            "04/16/2021 17:53:40 - INFO - utils_ner -   tokens: [CLS] خرداد [UNK] [UNK] کیهان [UNK] میراث سناتور مصطفی مصباح ##زاده [UNK] ساله شد کیهان لندن تنها رسانه ایرانی در تبعید است که [UNK] از جنگ دوم جهانی تاکنون قدمت و یک موسسه غصب شده در تهران [UNK] دارد [SEP]\n",
            "04/16/2021 17:53:40 - INFO - utils_ner -   input_ids: 2 3604 1 1 8567 1 5302 10842 7508 13018 4067 1 3503 2087 8567 6236 2678 3080 2732 2028 14260 2045 2046 1 2036 2941 2969 2753 3573 10972 331 2076 3914 30459 2110 2028 2402 1 2192 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/16/2021 17:53:40 - INFO - utils_ner -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/16/2021 17:53:40 - INFO - utils_ner -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/16/2021 17:53:40 - INFO - utils_ner -   label_ids: -100 12 12 12 3 12 12 12 4 10 -100 12 12 12 3 1 12 12 2 12 12 12 12 12 12 0 6 6 12 12 12 12 12 12 12 12 1 12 12 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
            "04/16/2021 17:53:40 - INFO - utils_ner -   *** Example ***\n",
            "04/16/2021 17:53:40 - INFO - utils_ner -   guid: test-2\n",
            "04/16/2021 17:53:40 - INFO - utils_ner -   tokens: [CLS] زین سرای بیکسی کس مج ##و محنت عاشقی ز بیکس مج ##و طرب عاشقانهای ##ی رواد ##ار کنون به کس و بیکس کنون عشق مج ##و مجتبی الوندی [SEP]\n",
            "04/16/2021 17:53:40 - INFO - utils_ner -   input_ids: 2 8100 15277 99583 2640 2171 1154 57111 24701 316 43504 2171 1154 56918 43553 1158 68136 2027 6189 2031 2640 331 43504 6189 6090 2171 1154 9082 64746 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/16/2021 17:53:40 - INFO - utils_ner -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/16/2021 17:53:40 - INFO - utils_ner -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/16/2021 17:53:40 - INFO - utils_ner -   label_ids: -100 12 12 12 12 12 -100 12 12 12 12 12 -100 12 12 -100 12 -100 12 12 12 12 12 12 12 12 -100 4 10 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
            "04/16/2021 17:53:40 - INFO - utils_ner -   *** Example ***\n",
            "04/16/2021 17:53:40 - INFO - utils_ner -   guid: test-3\n",
            "04/16/2021 17:53:40 - INFO - utils_ner -   tokens: [CLS] تا حالا چیزی از اپولو [UNK] شنیدید سفر ناموفق ناسا به ماه که بخاطر اشکالی که توی فضاپیما پیش اومد مجبور به فرود اضطراری شد و هرگز به ماه نرسید توی اون سفر جان ( جک ) سوی ##گرت داره به مرکز ناسا در هوستون گزارش میده و این عبارت رو میگه [UNK] هوستون ما یه مشکل داریم [UNK] معنی این اصطلاح ( [UNK] ) [SEP]\n",
            "04/16/2021 17:53:40 - INFO - utils_ner -   input_ids: 2 2093 3826 3678 2036 27304 1 37707 3077 13870 12597 2031 2306 2046 10014 13260 2046 5545 26508 2226 22092 5187 2031 4085 10834 2087 331 5776 2031 2306 9732 5545 5726 3077 3059 9 12178 10 2629 90500 11723 2031 3040 12597 2028 43846 2248 2422 331 2042 4726 2071 19534 1 43846 2179 5719 2524 3194 1 5749 2042 6680 9 1 10 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/16/2021 17:53:40 - INFO - utils_ner -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/16/2021 17:53:40 - INFO - utils_ner -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/16/2021 17:53:40 - INFO - utils_ner -   label_ids: -100 12 12 12 12 12 12 12 12 12 3 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 4 12 4 12 4 -100 12 12 12 3 12 1 12 12 12 12 12 12 12 12 1 12 12 12 12 12 12 12 12 12 12 12 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
            "04/16/2021 17:53:40 - INFO - utils_ner -   *** Example ***\n",
            "04/16/2021 17:53:40 - INFO - utils_ner -   guid: test-4\n",
            "04/16/2021 17:53:40 - INFO - utils_ner -   tokens: [CLS] وظیفه اصلی ارتش حفاظت از ایران هست و معمولا کمبود بودجه دارند و امکانات کم ولی وظی ##ه اصلی سپاه حفظ نظام هست به هر شرایطی و معمولا بهترین بودجه و امکانات نظامی در اختیارشان هست [SEP]\n",
            "04/16/2021 17:53:40 - INFO - utils_ner -   input_ids: 2 4549 2832 4207 5120 2036 2119 2209 331 4352 4854 3319 2522 331 4499 2230 2752 4385 1177 2832 4008 3530 2834 2209 2031 2202 4258 331 4352 3362 3319 331 4499 3624 2028 22563 2209 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/16/2021 17:53:40 - INFO - utils_ner -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/16/2021 17:53:40 - INFO - utils_ner -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/16/2021 17:53:40 - INFO - utils_ner -   label_ids: -100 12 12 3 12 12 1 12 12 12 12 12 12 12 12 12 12 12 -100 12 3 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
            "04/16/2021 17:53:40 - INFO - utils_ner -   *** Example ***\n",
            "04/16/2021 17:53:40 - INFO - utils_ner -   guid: test-5\n",
            "04/16/2021 17:53:40 - INFO - utils_ner -   tokens: [CLS] اخه تو عکس ##ایی که منتشر شد چند تا هواپیما هم بود کو هواپیماها ##ش ایسنا بلف میای روح و روان مردم دربند ظلم رو با شوخی ##ای خبری ##ت قلقلک نده بذار به درد خودرو و سکه و دلار و بورس و دارو و مایحتاج زندگی و مسکن و بسوز ##یم و زیر فشار انقلاب بسازیم وخوش باشیم که در طریقت ما کافری ##ست رنجی ##دن [SEP]\n",
            "04/16/2021 17:53:40 - INFO - utils_ner -   input_ids: 2 26485 2092 3679 2100 2046 2979 2087 2429 2093 5340 2063 2083 2873 11797 1176 3715 42943 15899 2845 331 4139 2342 22666 9539 2071 2037 9595 2026 2814 1174 55802 6176 47144 2031 4810 2331 331 4579 331 2707 331 3112 331 3955 331 20627 2763 331 2794 331 33683 2053 331 2516 3657 2858 15759 77479 3545 2046 2028 30651 2179 90811 2030 37765 2805 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/16/2021 17:53:40 - INFO - utils_ner -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/16/2021 17:53:40 - INFO - utils_ner -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "04/16/2021 17:53:40 - INFO - utils_ner -   label_ids: -100 12 12 12 -100 12 12 12 12 12 12 12 12 12 12 -100 3 12 12 12 12 12 12 12 12 12 12 12 -100 12 -100 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 12 -100 12 12 12 12 12 12 12 12 12 12 12 12 -100 12 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100\n",
            "2021-04-16 17:53:41.499436: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:454] The `assert_cardinality` transformation is currently not handled by the auto-shard rewrite and will be removed.\n",
            "2021-04-16 17:53:41.499606: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:656] In AUTO-mode, and switching to DATA-based sharding, instead of FILE-based sharding as we cannot find appropriate reader dataset op(s) to shard. Error: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_2\"\n",
            "op: \"FlatMapDataset\"\n",
            "input: \"TensorDataset/_1\"\n",
            "attr {\n",
            "  key: \"Targuments\"\n",
            "  value {\n",
            "    list {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"f\"\n",
            "  value {\n",
            "    func {\n",
            "      name: \"__inference_Dataset_flat_map_flat_map_fn_68033\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_shapes\"\n",
            "  value {\n",
            "    list {\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "      shape {\n",
            "        dim {\n",
            "          size: -1\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "attr {\n",
            "  key: \"output_types\"\n",
            "  value {\n",
            "    list {\n",
            "      type: DT_INT32\n",
            "      type: DT_INT32\n",
            "      type: DT_INT32\n",
            "      type: DT_INT64\n",
            "    }\n",
            "  }\n",
            "}\n",
            ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n",
            "04/16/2021 17:53:41 - INFO - utils_ner -   ***** Running Prediction *****\n",
            "04/16/2021 17:53:41 - INFO - utils_ner -     Num examples in dataset = 303\n",
            "04/16/2021 17:53:41 - INFO - utils_ner -     Batch size = 8\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "04/16/2021 17:53:47 - WARNING - tensorflow -   The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "04/16/2021 17:53:47 - WARNING - tensorflow -   The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "04/16/2021 17:53:49 - INFO - __main__ -   \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         EVE       0.25      0.29      0.27        14\n",
            "         LOC       0.83      0.85      0.84       221\n",
            "         NAT       0.72      0.87      0.79        30\n",
            "         ORG       0.65      0.67      0.66       129\n",
            "         PER       0.88      0.91      0.89       244\n",
            "         POG       0.83      0.68      0.75        22\n",
            "\n",
            "   micro avg       0.79      0.82      0.81       660\n",
            "   macro avg       0.69      0.71      0.70       660\n",
            "weighted avg       0.80      0.82      0.81       660\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"run_tf_ner.py\", line 422, in <module>\n",
            "    main()\n",
            "  File \"run_tf_ner.py\", line 400, in main\n",
            "    with open(os.path.join(data_args.data_dir, \"test.txt\"), \"r\") as f:\n",
            "NameError: name 'data_args' is not defined\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m6XQQZaRkPYu"
      },
      "source": [
        "!pip install -q transformers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FIqsqGnYHQI3"
      },
      "source": [
        "import tensorflow as tf\n",
        "from transformers import BertTokenizer, TFBertForPreTraining\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "model = TFBertForPreTraining.from_pretrained('bert-base-uncased')\n",
        "input_ids = tf.constant(tokenizer.encode(\"Hello, my dog is cute\", add_special_tokens=True))[None, :]  # Batch size 1\n",
        "outputs = model(input_ids)\n",
        "prediction_scores, seq_relationship_scores = outputs[:2]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ctkfSnOdkGyd"
      },
      "source": [
        "getattr(model, 'bert')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ksz-_fngke-R"
      },
      "source": [
        "from transformers import TFBertForTokenClassification\n",
        "model = TFBertForTokenClassification.from_pretrained('bert-base-uncased')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QRhzd7H2f2Ih"
      },
      "source": [
        "model.layers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s_ACLQQegJx9"
      },
      "source": [
        "model.layers[2].__dict__"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fXwPixA-aAvN"
      },
      "source": [
        "getattr(model, 'bert').count_params()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ci7BpG-pjRxH"
      },
      "source": [
        "model.layers[2].count_params()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lyd4RiC6hf-e"
      },
      "source": [
        "from keras.utils.vis_utils import plot_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LAaAfwbwhj6A"
      },
      "source": [
        "plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fnc37IAdf4q2"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AQiRQnIwabIc"
      },
      "source": [
        "model.layers[0]._layers[1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yX8534Jdf611"
      },
      "source": [
        "model.layers[0]._layers[2]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SH9e5Ia1fhLr"
      },
      "source": [
        "model.layers[0]._layers[2]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tQWjnx9dfiMf"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}