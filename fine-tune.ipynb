{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tempo.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/overfit-ir/persian-twitter-ner/blob/master/fine-tune.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ebZsy7HYObGg"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nF-7m57sBgdp"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M1Awb1uBEExX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "835ec8e2-745a-4826-d016-f60047525775"
      },
      "source": [
        "!wget -q --show-progress 'https://raw.githubusercontent.com/overfit-ir/persian-twitter-ner/master/twitter_data/persian-ner-twitter-data/train.txt'\n",
        "!wget -q --show-progress 'https://raw.githubusercontent.com/overfit-ir/persian-twitter-ner/master/twitter_data/persian-ner-twitter-data/test.txt'\n",
        "!wget -q --show-progress 'https://raw.githubusercontent.com/overfit-ir/persian-twitter-ner/master/twitter_data/persian-ner-twitter-data/dev.txt'\n",
        "!mkdir data && mv train.txt data && mv test.txt data && mv dev.txt data"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train.txt           100%[===================>]   2.20M  --.-KB/s    in 0.1s    \n",
            "test.txt            100%[===================>] 108.10K  --.-KB/s    in 0.02s   \n",
            "dev.txt             100%[===================>] 160.83K  --.-KB/s    in 0.03s   \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YuuoB7sxjk0Y"
      },
      "source": [
        "# Benchmark2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y0dGPIj5MTqW"
      },
      "source": [
        "!cat data/train.txt | grep -v \"^#\" | cut -f 1,2 | tr '\\t' ' ' > train.txt.tmp\n",
        "!cat data/test.txt | grep -v \"^#\" | cut -f 1,2 | tr '\\t' ' ' > test.txt.tmp\n",
        "!cat data/dev.txt | grep -v \"^#\" | cut -f 1,2 | tr '\\t' ' ' > dev.txt.tmp"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ui3HZfRwfwTH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f089391-c16b-412a-b73e-b3186e6e884c"
      },
      "source": [
        "!git clone https://github.com/huggingface/transformers"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'transformers'...\n",
            "remote: Enumerating objects: 24, done.\u001b[K\n",
            "remote: Counting objects: 100% (24/24), done.\u001b[K\n",
            "remote: Compressing objects: 100% (21/21), done.\u001b[K\n",
            "remote: Total 62634 (delta 6), reused 9 (delta 0), pack-reused 62610\u001b[K\n",
            "Receiving objects: 100% (62634/62634), 47.73 MiB | 13.69 MiB/s, done.\n",
            "Resolving deltas: 100% (44354/44354), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VZHBg4CauUCM",
        "outputId": "7903ec0b-9c1c-4211-f7e1-220345427ebb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip -q install transformers/\n",
        "!pip -q install sentencepiece"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[K     |████████████████████████████████| 3.2MB 4.1MB/s \n",
            "\u001b[K     |████████████████████████████████| 890kB 33.7MB/s \n",
            "\u001b[?25h  Building wheel for transformers (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/67/e42bd1181472c95c8cda79305df848264f2a7f62740995a46945d9797b67/sentencepiece-0.1.95-cp36-cp36m-manylinux2014_x86_64.whl (1.2MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2MB 4.0MB/s \n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.95\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Atfg8k8Ajqv-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2a4ba08-6ca3-451d-e8ec-1930b1a064ed"
      },
      "source": [
        "!wget \"https://raw.githubusercontent.com/stefan-it/fine-tuned-berts-seq/master/scripts/preprocess.py\""
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-02-17 11:25:25--  https://raw.githubusercontent.com/stefan-it/fine-tuned-berts-seq/master/scripts/preprocess.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 991 [text/plain]\n",
            "Saving to: ‘preprocess.py.1’\n",
            "\n",
            "\rpreprocess.py.1       0%[                    ]       0  --.-KB/s               \rpreprocess.py.1     100%[===================>]     991  --.-KB/s    in 0s      \n",
            "\n",
            "2021-02-17 11:25:25 (41.7 MB/s) - ‘preprocess.py.1’ saved [991/991]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "itWy78SnkBlk"
      },
      "source": [
        "!python3 preprocess.py dev.txt.tmp HooshvareLab/bert-base-parsbert-uncased 256 > dev.txt\n",
        "!python3 preprocess.py train.txt.tmp HooshvareLab/bert-base-parsbert-uncased 256 > train.txt\n",
        "!python3 preprocess.py test.txt.tmp HooshvareLab/bert-base-parsbert-uncased 256 > test.txt"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vdHj8GTrlBnr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cca11c87-3cfe-4f20-a39f-348bc30abd92"
      },
      "source": [
        "!pip -q install -r transformers/examples/token-classification/requirements.txt"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 51kB 2.6MB/s \n",
            "\u001b[K     |████████████████████████████████| 184kB 5.7MB/s \n",
            "\u001b[K     |████████████████████████████████| 102kB 4.9MB/s \n",
            "\u001b[K     |████████████████████████████████| 245kB 7.5MB/s \n",
            "\u001b[K     |████████████████████████████████| 20.7MB 1.4MB/s \n",
            "\u001b[?25h  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hdElNDJWOZGe"
      },
      "source": [
        "!pip -q install conllu"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rgZbOD--k4LN"
      },
      "source": [
        "!mkdir processed_data\n",
        "!mv train.txt processed_data/ && mv test.txt processed_data/ && mv dev.txt processed_data/"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iw_LDa1JpOcf"
      },
      "source": [
        "!cat processed_data/train.txt processed_data/test.txt processed_data/dev.txt | cut -d \" \" -f 2 | grep -v \"^$\"| sort | uniq > labels.txt"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oYON8_WAx0MU"
      },
      "source": [
        "! cp /content/transformers/examples/legacy/token-classification/utils_ner.py /content/transformers/examples/token-classification\n",
        "! cp /content/transformers/examples/legacy/token-classification/tasks.py /content/transformers/examples/token-classification"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oQKW9EiUlYVk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "404f8b3c-c0a1-4b7f-ae1a-48d8a34ede9d"
      },
      "source": [
        "!python3 transformers/examples/token-classification/run_ner.py --data_dir ./processed_data/ \\\n",
        "--labels labels.txt \\\n",
        "--model_name_or_path HooshvareLab/bert-base-parsbert-uncased \\\n",
        "--output_dir eval/ \\\n",
        "--max_seq_length  256 \\\n",
        "--per_device_train_batch_size 32 \\\n",
        "--save_steps 750 \\\n",
        "--seed 1 \\\n",
        "--do_train \\\n",
        "--do_eval \\\n",
        "--do_predict"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-02-17 11:43:39.893643: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
            "Traceback (most recent call last):\n",
            "  File \"transformers/examples/token-classification/run_ner.py\", line 455, in <module>\n",
            "    main()\n",
            "  File \"transformers/examples/token-classification/run_ner.py\", line 156, in main\n",
            "    model_args, data_args, training_args = parser.parse_args_into_dataclasses()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/transformers/hf_argparser.py\", line 180, in parse_args_into_dataclasses\n",
            "    obj = dtype(**inputs)\n",
            "  File \"<string>\", line 13, in __init__\n",
            "  File \"transformers/examples/token-classification/run_ner.py\", line 134, in __post_init__\n",
            "    raise ValueError(\"Need either a dataset name or a training/validation file.\")\n",
            "ValueError: Need either a dataset name or a training/validation file.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "INDb-IQoO6Lv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00961567-d770-4d48-bc45-e2c8fb3d07a4"
      },
      "source": [
        "!zip -r eval.zip eval"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  adding: eval/ (stored 0%)\n",
            "  adding: eval/checkpoint-2250/ (stored 0%)\n",
            "  adding: eval/checkpoint-2250/scheduler.pt (deflated 49%)\n",
            "  adding: eval/checkpoint-2250/config.json (deflated 54%)\n",
            "  adding: eval/checkpoint-2250/pytorch_model.bin (deflated 8%)\n",
            "  adding: eval/checkpoint-2250/optimizer.pt (deflated 41%)\n",
            "  adding: eval/checkpoint-2250/trainer_state.json (deflated 60%)\n",
            "  adding: eval/checkpoint-2250/training_args.bin (deflated 45%)\n",
            "  adding: eval/test_predictions.txt (deflated 71%)\n",
            "  adding: eval/test_results.txt (deflated 34%)\n",
            "  adding: eval/config.json (deflated 54%)\n",
            "  adding: eval/checkpoint-750/ (stored 0%)\n",
            "  adding: eval/checkpoint-750/scheduler.pt (deflated 49%)\n",
            "  adding: eval/checkpoint-750/config.json (deflated 54%)\n",
            "  adding: eval/checkpoint-750/pytorch_model.bin (deflated 8%)\n",
            "  adding: eval/checkpoint-750/optimizer.pt (deflated 41%)\n",
            "  adding: eval/checkpoint-750/trainer_state.json (deflated 45%)\n",
            "  adding: eval/checkpoint-750/training_args.bin (deflated 45%)\n",
            "  adding: eval/special_tokens_map.json (deflated 40%)\n",
            "  adding: eval/eval_results.txt (deflated 33%)\n",
            "  adding: eval/pytorch_model.bin (deflated 8%)\n",
            "  adding: eval/checkpoint-1500/ (stored 0%)\n",
            "  adding: eval/checkpoint-1500/scheduler.pt (deflated 49%)\n",
            "  adding: eval/checkpoint-1500/config.json (deflated 54%)\n",
            "  adding: eval/checkpoint-1500/pytorch_model.bin (deflated 8%)\n",
            "  adding: eval/checkpoint-1500/optimizer.pt (deflated 41%)\n",
            "  adding: eval/checkpoint-1500/trainer_state.json (deflated 57%)\n",
            "  adding: eval/checkpoint-1500/training_args.bin (deflated 45%)\n",
            "  adding: eval/vocab.txt (deflated 62%)\n",
            "  adding: eval/training_args.bin (deflated 45%)\n",
            "  adding: eval/tokenizer_config.json (deflated 45%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VsXoweocoGFr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4558b012-0a0a-449a-804e-faa06e42f3ca"
      },
      "source": [
        "!zip -r runs.zip runs"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  adding: runs/ (stored 0%)\n",
            "  adding: runs/Jan28_05-40-21_c389095872f4/ (stored 0%)\n",
            "  adding: runs/Jan28_05-40-21_c389095872f4/events.out.tfevents.1611840450.c389095872f4.263.2 (deflated 29%)\n",
            "  adding: runs/Jan28_05-40-21_c389095872f4/events.out.tfevents.1611812466.c389095872f4.263.0 (deflated 54%)\n",
            "  adding: runs/Jan28_05-40-21_c389095872f4/1611812466.8290157/ (stored 0%)\n",
            "  adding: runs/Jan28_05-40-21_c389095872f4/1611812466.8290157/events.out.tfevents.1611812466.c389095872f4.263.1 (deflated 59%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WxCBReCKPZDK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf63ea9d-a0a0-4964-a1c6-7d42466e7cc1"
      },
      "source": [
        "!ls -lh"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 4.4G\n",
            "drwxr-xr-x  2 root root 4.0K Jan 28 05:38 data\n",
            "-rw-r--r--  1 root root 161K Jan 28 05:38 dev.txt.tmp\n",
            "drwxr-xr-x  5 root root 4.0K Jan 28 13:29 eval\n",
            "-rw-r--r--  1 root root 4.4G Jan 28 13:49 eval.zip\n",
            "-rw-r--r--  1 root root   74 Jan 28 05:39 labels.txt\n",
            "-rw-r--r--  1 root root  991 Jan 28 05:39 preprocess.py\n",
            "drwxr-xr-x  2 root root 4.0K Jan 28 13:27 processed_data\n",
            "drwxr-xr-x  3 root root 4.0K Jan 28 05:41 runs\n",
            "-rw-r--r--  1 root root 4.8K Jan 28 13:49 runs.zip\n",
            "drwxr-xr-x  1 root root 4.0K Jan 20 17:27 sample_data\n",
            "-rw-r--r--  1 root root 109K Jan 28 05:38 test.txt.tmp\n",
            "-rw-r--r--  1 root root 2.3M Jan 28 05:38 train.txt.tmp\n",
            "drwxr-xr-x 16 root root 4.0K Jan 28 05:38 transformers\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mIfVX62aZQFt"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}