{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.3 64-bit ('3.8.3')",
   "metadata": {
    "interpreter": {
     "hash": "d0870ed645fb27f1bd390e6a2c2d97d636644e4ac17d9620d795cd4fea4e8862"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import re\n",
    "\n",
    "def convert_lines_to_text(file_path, separator='\\t'):\n",
    "    file_path = Path(file_path)\n",
    "\n",
    "    raw_text = file_path.read_text().strip()\n",
    "    raw_docs = re.split(r'\\n\\t?\\n', raw_text)\n",
    "    token_docs = []\n",
    "    tag_docs = []\n",
    "    for doc in raw_docs:\n",
    "        tokens = []\n",
    "        tags = []\n",
    "        for line in doc.split('\\n'):\n",
    "            token, tag = line.split(separator, 1)\n",
    "            tokens.append(token)\n",
    "            tags.append(tag)\n",
    "        token_docs.append(tokens)\n",
    "        tag_docs.append(tags)\n",
    "\n",
    "    return token_docs, tag_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts, tags = convert_lines_to_text('twitter_data/persian-ner-twitter-data/train.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "masked_tweets = []\n",
    "for tweet, tweet_tags in zip(texts, tags):\n",
    "    masked_tweet = []\n",
    "    for word, tag in zip(tweet, tweet_tags):\n",
    "        if tag != 'O':\n",
    "            if random.uniform(0,1) < 0.2:\n",
    "                masked_tweet.append('[MASK]')\n",
    "            else:\n",
    "                masked_tweet.append(word)\n",
    "        else:\n",
    "            masked_tweet.append(word)\n",
    "    masked_tweets.append(masked_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "4552"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "org = [word for tweet, tweet_tags in zip(masked_tweets, tags) for word, tag in zip(tweet, tweet_tags) if 'ORG' in tag]\n",
    "len(org)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "896"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "org = [word for tweet, tweet_tags in zip(masked_tweets, tags) for word, tag in zip(tweet, tweet_tags) if 'ORG' in tag and word == '[MASK]']\n",
    "len(org)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "5974"
      ]
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "source": [
    "org = [word for tweet, tweet_tags in zip(masked_tweets, tags) for word, tag in zip(tweet, tweet_tags) if 'LOC' in tag]\n",
    "len(org)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1198"
      ]
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "source": [
    "org = [word for tweet, tweet_tags in zip(masked_tweets, tags) for word, tag in zip(tweet, tweet_tags) if 'LOC' in tag and word == '[MASK]']\n",
    "len(org)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "8624"
      ]
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "source": [
    "org = [word for tweet, tweet_tags in zip(masked_tweets, tags) for word, tag in zip(tweet, tweet_tags) if 'PER' in tag]\n",
    "len(org)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1725"
      ]
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "source": [
    "org = [word for tweet, tweet_tags in zip(masked_tweets, tags) for word, tag in zip(tweet, tweet_tags) if 'PER' in tag and word == '[MASK]']\n",
    "len(org)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1068"
      ]
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "source": [
    "org = [word for tweet, tweet_tags in zip(masked_tweets, tags) for word, tag in zip(tweet, tweet_tags) if 'EVE' in tag]\n",
    "len(org)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "205"
      ]
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "source": [
    "org = [word for tweet, tweet_tags in zip(masked_tweets, tags) for word, tag in zip(tweet, tweet_tags) if 'EVE' in tag and word == '[MASK]']\n",
    "len(org)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "523"
      ]
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "source": [
    "org = [word for tweet, tweet_tags in zip(masked_tweets, tags) for word, tag in zip(tweet, tweet_tags) if 'POG' in tag]\n",
    "len(org)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "121"
      ]
     },
     "metadata": {},
     "execution_count": 30
    }
   ],
   "source": [
    "org = [word for tweet, tweet_tags in zip(masked_tweets, tags) for word, tag in zip(tweet, tweet_tags) if 'POG' in tag and word == '[MASK]']\n",
    "len(org)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "868"
      ]
     },
     "metadata": {},
     "execution_count": 31
    }
   ],
   "source": [
    "org = [word for tweet, tweet_tags in zip(masked_tweets, tags) for word, tag in zip(tweet, tweet_tags) if 'NAT' in tag]\n",
    "len(org)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "161"
      ]
     },
     "metadata": {},
     "execution_count": 32
    }
   ],
   "source": [
    "org = [word for tweet, tweet_tags in zip(masked_tweets, tags) for word, tag in zip(tweet, tweet_tags) if 'NAT' in tag and word == '[MASK]']\n",
    "len(org)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('twitter_data/persian-ner-twitter-data/masked_trainset.txt', 'w') as file:\n",
    "    for tweet_text, tweet_tags in zip(masked_tweets, tags):\n",
    "        for word, tag in zip(tweet_text, tweet_tags):\n",
    "            file.write(word + '\\t' + tag + '\\n')\n",
    "        file.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}